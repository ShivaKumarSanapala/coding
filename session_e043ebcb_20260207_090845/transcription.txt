# Live Transcription Session: session_e043ebcb_20260207_090845
# Started: 2026-02-07T09:08:45.995898
# Language: en
# Model: medium
# Accumulation Duration: 5.0s
# Save Audio: No
# ============================================================

[09:09:13] I think it is 9 or 8, I think. Can start, right? Shall we start?
[09:09:26] Yes, yes, please. OK, great. OK, so let us start the session. Good morning, everyone. Hope everybody is doing good.
[09:09:40] Today we'll start with Keras framework, another deep learning framework. We'll discuss practically how do we implement Keras and in real time when you are deploying your deep
[09:09:52] learning models. How do you make that Keras available in the train model? So I won't
[09:10:06] the technical implementations and I'll use the whiteboard again as usual. So let us start with what is first Keras. What do you know about the Keras and why do we use
[09:10:21] here as we'll see. So you know, what is a Jup neural network, right? So when we thought of classical machine learning, classical machine learning have a limitation that it cannot handle
[09:10:37] huge amount of the data, and it cannot take classical, you know, sorry, the structured data and structured data. So to come out of the problem, they came across with deep neural network, which is a mimic of a human brain where we talk about the
[09:10:57] perceptron so the first model is perceptron model then we came up with multi-layer perceptron model MLP then we got the deep neural networks again in the deep neural networks we got about convolution neural networks for image and the recurrent neural network for the text processing LSTM like the
[09:11:18] different models has been developed. Now, to implement these models, apart from Python, we need a framework so that we can build these models. So to build these models, they came up with the PyTorch, the JAX, you have TensorFlow, then we got the Keras. So why
[09:11:35] with the nowadays people are more towards the Keras, we'll see. So basically you start with Keras is a deep neural network framework we can say, which is written completely in Python. Basically it is designed for fast experimentation
[09:11:51] Deep learning models. So originally, it was created by Charlotte, who is a part of a one IRO research project. So there has been grown into like one of the most widely used and adapted
[09:12:04] deep learning frameworks with over 300, so 3 million developers in the worldwide. Okay. Okay. So why we use Keras generally? You can say
[09:12:15] that it is a Python native. Then it has a modular design.
[09:12:25] Then it is multi backend. And then we have around three
[09:12:37] and plus developer communities there. So this is like, you know, basically why do we use Keras framework?
[09:12:49] And in Keras, we have three different kinds of models. So before that, let me explain you
[09:12:57] Oh.
[09:13:07] get us one point.
[09:13:18] which is a standard model. Then in 2019 they came up with Keras 2.x which is
[09:13:31] integrated into TensorFlow. You know TensorFlow is a Google framework, right? So generally we used to use TensorFlow, but now they integrated Keras into
[09:13:46] TensorFlow using Keras and TensorFlow both are the same. Backend will be TensorFlow only, but the wrapper is the Keras, which will make it easy for that. Then in 2023, we got Keras three
[09:14:02] Now we are with 25, we have Keras 3.13 something like that we have. So what is the difference here?
[09:14:19] and it is supporting only two kinds of Thano and the TensorFlow backends. Then 2.x onwards, they integrated into TensorFlow. So when you install TensorFlow, automatically Keras will be installed and through Keras,
[09:14:41] Keras. That means we can access Keras through TensorFlow object. And it became the official and high-level API of Google then. So Google integrated into that. So the Charlotte is one of the employees of Google only. He was
[09:15:04] framework, Keras actually. Then coming to 3.0, which is not only supporting only Theano and TensorFlow, then it is supporting the multi-backend. That multi-backend in the sense, if you are developing a model in Keras, you can deploy using a JAGS, TensorFlow, PyTorch also, OpenVINO is there.
[09:15:31] is where it is. Now, after that, here, 2025, we got as a LiteRT export, we call it. That means it is going to support with ONNX. ONNX in the sense, it is going to support lightweight edge devices. For example, you want to deploy the model into mobile devices, it is possible. And then it has been given the quantization. So nowadays, we are using the term
[09:15:59] quantum computers, right? The quantization in the sense converting the model into the smaller format that also supported in 2025. That means if you build a model in Keras, for example, the model came up with say that 500 MB of the size, right? So we can use quantization with the same capacity, means same kind of output, but the size will be decreased. We'll see that with the practical, okay?
[09:16:22] That is the 2025, we got the latest model. So in the latest 2025, it supports a lot of the framework and it is like industry adapted. Now the question is why we need to use Keras? First thing is we say that it is fast prototyping. Suppose if you want to build any POC kind of thing immediately, so that is very fast we can build through.
[09:16:43] second thing is it has we call it as a best-in-class performance so when you are deploying the model the model performance is better that means when you are deploying on to the edge devices on to the like you know GPU CPUs like that and it support full architecture support full architecture support in the sense you know about
[09:17:06] So for example, we know convolution neural networks, any architecture, it's supposed like that. So most of the deep learning architectures starting from convolution neural networks, recurrent neural networks, transformers, and you have hybrid networks, then we have GANs, Generative Adversary Networks, all of the architectures they'll support.
[09:17:28] And next one, fourth one, we say that as a performance, it supports seamless hardware. So what do you mean by seamless hardware? That means it runs on CPU, it runs on GPU, it runs on TPU without any code changes and scales from automatically when you deploy the model, it scales from laptop prototyping to data center scale.
[09:17:44] distributed training happens okay and next one is we can talk about the portability so portability in the sense we can once you write the code in Keras you can import export that particular module as a
[09:18:09] PyTorch module you can export. As a TensorFlow model, you can save. As a JAX function, you can save it. Or you can use the TF Lite format so that you can deploy onto the mobile and edge devices. This is the next. Another one important thing is as it is an open source.
[09:18:35] Okay, and you can see the community also, right? So we have around 3 million community for Keras. Okay, so now, once you understand why we need Keras, from these features, we can understand that Keras is a growing framework for any deep learning models, architectures, we can say.
[09:19:01] if you are building a conversion neural networks or if you are building recurrent neural networks or GANs or anything, we understand that Keras is one of the best framework due to these properties, like six properties what I mentioned. Easily you can write the code. You can see, you can write a stack of layers very easily and we see practically how do we implement all those things. I'll stop here for
[09:19:19] Any questions? Okay, good. Now, we got the importance of the Keras framework. And then, for example, if you are building any architecture in
[09:19:34] how many ways we can build the Keras models. So to build the Keras models, we have three API styles. So first thing is we call it as a sequential API.
[09:19:46] Second, we'll talk about functional API. Then third, model.
[09:20:02] subclassing so like when you write for example if you write if i ask you write a program to check given number is a prime or not right
[09:20:20] revenue in Python program. So generally what you write, if I say enter a number, then you take the number, you'll check whether it is less than or equal to one, or you will take the number or divide by itself
[09:20:41] the code. So then some people, what they will do, okay, instead of writing the code for the modularity, they put it in a function saying that it is something like, you know, find prime function, they will write it inside the function, they will give a parameter and they take the parameters, then they'll write the code.
[09:21:07] the third one what he will do he will define a class and here he is going to write the function here there's a class he will write the function and he will call the function here just by passing the number so for a simple to check given number is a prime number in how many ways we have written a different ways are there for example if you consider people
[09:21:44] can write in different way. But basically, if I start, I can say, okay, people, they write a step by step lines they are writing. This is one way. Second is he's defining the function. Third way, he's defining the class. And in one of the, like, you know, another notebook, he's calling that class, the object of the class is calling the function. So similar way, when you're writing a Keras framework, we can define the deep learning architecture in Keras.
[09:22:19] One is a sequential API. That means stack of layers, we can do it. Functional API, we can define as a function. Third one is model subclassing. So we can keep a function, particular function in a class, and then we can import the class. So there are three different ways of writing Keras models. We'll see, we'll start with the first sequential. Okay. So in sequential model, we are going to have first thing is a linear stack of layers.
[09:22:48] So which is very simple. What do you mean by linear stack of layers? So we know that in deep learning, when you're defining, first we have a input layer, right? Which is with some of the parameters we have. Then we have some hidden layers, neural networks. So we have some hidden layers. Then we are going to have finally output layer. So input layer, output layer, then we have some hidden layers. Here we can define
[09:23:14] So first I can define one layer, then I can add to the second layer, then add third layer, fourth layer, fifth layer, then sixth layer like that, okay? And this works for single input, single output only. What do you mean by single input and single output? Single input and single output. For example, if you consider Iris data, Iris data is a single input which consists of four features.
[09:23:39] features, sepal length, sepal width, petal length and petal width. Now when it goes in, what is the prediction? Either it is going to be a setosa or vergenica, that means single problem statement and output also a single only. So either you classify iris setosa or find the house prices or check the given person, given animal is, for example, elephant or something.
[09:23:57] okay so single input single output only right and here we are going to create by stacking layers it by stacking layers one after another go ahead Ashok yes a small question actually
[09:24:18] single input single output I understood what is the other other thing sir other thing is sometimes we can get a two problem statements and waiting in the one output or two output that comes in functional API okay I mean so far we did not see that that's the reason I that's so far we are seeing in class anymore
[09:24:35] learning algorithms, one input and one output only, okay? Today, we'll see two inputs are one input, two output also. Thanks, sir. Thank you. Yeah. Okay, this is best for quick prototypes.
[09:24:52] And if you want to write some simple classifier, then this is the best one. Okay. So this is a sequential model. So what I will do, first of all, I will explain what is a sequential model. Okay.
[09:25:14] So then I'll write down the code and then we'll come back to the functional, then we'll write down the code, then we'll write down the model subclassing. So that way you can understand it one by one. So first let us completely understand what is a sequential model, okay? So now here you see,
[09:25:34] Like in the sequential model, we are going to have a linear stack of layers, single input on single output. And how do you create? Create by stacking the layers. And best for quick prototypes and simple classifier. Now, how do you build that building step? First of all, we need to define architecture.
[09:25:49] Second, compile the model. Third, train. That is nothing but fit the model. And the next one, we evaluate them.
[09:26:06] So first of all, we need to understand, define the model. So I hope you understand like, you know, how do you define the architecture, compile the model, you know.
[09:26:25] how to train the models you have seen and how do we evaluate the model. So then here we have like when you're defining the architecture we are using neural network right. So when you're using neural network generally in neural network we have some of the parameters
[09:26:38] parameters we have, right? So we can say neural network, model, parameters. Okay, so let me first start with architecture parameters.
[09:26:50] Second, training parameters. Third, evaluation parameters.
[09:27:05] So when you're defining any neural network, so generally we are going to have model parameters. So here we have, first of all, number of layers.
[09:27:17] generally we call it as a depth. Second we have neurons per layer.
[09:27:29] So we call it as a width. Then what is a layer connectivity pattern?
[09:27:38] Next, activation function.
[09:27:52] So next, if you have something like a dropout, OK? And then we have batch.
[09:28:06] normalization. This comes into architecture parameters. Coming to the training parameters, we are going to have an optimizer. So in the optimized
[09:28:24] For example, Adam, Stochastic Gradient Distance JD, Adam W, Lion, like different optimizers will be there. Then we are going to have a last function. Inside the training, we need to define this model parameter.
[09:28:41] And then we can define the learning rate. Then we can define how many number of epochs. Then we can define what is the batch size. And then coming to the evaluation, either we can go with the accuracy.
[09:28:59] Then we can go with the confusion matrix. And then we can go with the train, test, validation split. And sometimes we go with the list stopping, and then we go with the cross validation.
[09:29:16] So these are some of the model neural network parameters. So when you talk about these parameters model, you might have seen when they define a convolution neural network or when you define recurrent neural networks, when you define
[09:29:35] any neural network, deep neural network, when you have seen the architectural parameters, architectural parameter in the sense like how many number of layers we need, how many number of neurons we are going to consist of, all those things we call it as architecture. So for example, let us take
[09:30:05] a real example. Let us take Iris data sample, simple. I have Iris data. Iris data is a classification problem, right? So which is going to have multi-class classification. Why? Because the target column consists of Setosa, Virginica, Vericosa, and Setosa, Virginica, Vericosa, right? Three only, correct?
[09:30:30] So now, here input how many features we have. For example, I have one, two, three, four features. That is sepal length, sepal width, petal length, and petal width. Now let us build the architecture. So I'm going to have three hidden layers. For example, which is say I have eight neurons. And then something say 10.
[09:30:55] neurons again ten neurons and finally I'm going to have a three neurons as a output layer so in input layer how many neurons we have four neurons correct that means sepal length is going to have one neuron sepal width one neuron petal length and petal width then I have defined eight neurons and ten neurons ten neurons and finally output layer consists of three
[09:31:24] So I'm going to use a softmax. From that, I can define whichever is having the highest probability. That will be my target column. Correct? So now, if you see the architecture parameter, here we say number of layers is the depth. Now, how many layers we have now? Input layer, three hidden layers, and output layer. Totally, this is known as a width. Depth, we call it. So how much depth? Then neurons per layer.
[09:31:59] So, what is the highest width now? For every layer, we have how many here? I got 8, 10, 10. So, highest layer neuron is 10. So, what is the width now? 10 neurons. So, then connectivity pattern, how I'm going to connect and what kind of activation functions we are using. If I'm using any dropout, I can use the dropout here. Otherwise, I can go with the batch navigation also, okay? So, now, then we'll go with the optimizer. So, before that, I want
[09:32:21] So generally when you look at the neural network, how is the neural network? This is sepal length, sepal width, petal length, and petal length. Now this connect to
[09:32:31] like this.
[09:32:42] So every neuron will connect with another neuron. Yes or no?
[09:32:54] Before jumping into the coding part, do you have any questions?
[09:33:10] Yes, I should go ahead. Yes sir, one question sir, I mean generic only. Generally sir, this output layer I am talking about. Output layer, let us take, right now we have three different
[09:33:27] In our case, we have three different things. That's why we are taking two neurons. Why don't we use only one? As neuron contains values from 0 to 255, why don't you use single neuron?
[09:33:47] 0 to 255. Yeah, each neuron can have a value from 0 to 255, right? Who said? That is my understanding, sir. No. No, no, no. Don't put any value for a neuron, okay? Okay, okay. Fixed cell value is 0 to 255, sir.
[09:34:11] So when you're taking image, pixel value but again we optimize that will become 0 to 1 only. And one more thing is that in the hidden layer thing right, so I'm talking about from the convolution layer point of view, we have some input let us say some x, then we made some 2x, then
[09:34:34] we made again. Next is previous into multiplied with 2x like that we are increasing. Is there any particular order like we have to increase or we can maintain save number? No, nothing. We don't have any thumb rule or any order. This is completely hit and run. So remember, complete machine learning is hit and run only. Okay, so there is
[09:34:59] to get this many neurons or this many. It is completely depends upon the experience you can define and after the output you are looking at, you can make number of layers you can increase or number of neurons you can increase like that. Okay. Thanks sir. Thank you. Sir, one more question. Instead of using all these hidden layers,
[09:35:26] Why don't we go for MLPs or multilayer perceptrons? Multilayer perceptron is a different architecture and we are talking about deep neural networks, right? So deep neural networks is one step ahead of the multi-neural networks. So when you combine the neural networks, that's where you're getting the deep neural networks. Again, going back to multi-neural networks doesn't have
[09:35:58] I have no idea. That's why I'm asking you. So here, actually, first we started with Perceptron model. It was only able to classify linear problems. Nonlinear, it was unable to. Then we came up with multi-layer Perceptron, introduced two layers. Then the thinking process increased with deep network. So that is a step ahead. So the combination is actually, we can say that Perceptron
[09:36:41] to three, to four, to four, something like that, right? The multiples. So this is, we can say, think like if you're taking a part is multi-layer perceptron only, the combination of multi-layer perceptron is the deep neural networks. Yeah. Rakesh, thank you. Yeah. Sir, I don't know if I'm jumping ahead, but are there any rules or best practices in terms of which activation function to choose for a classification versus a regression problem?
[09:37:43] Yeah, yeah, we'll talk about that now when I'm writing the code, but I will do that. Yeah. Yeah. Okay. I think, who is there? Somebody raised their hand and he says. Yes, sir. I'm Ram, actually. So, with respect to this, it's purely sit on top of the tensor, I mean tensor, or it will also have their own framework because in your site. Okay. In your slide you have been written that it is either tensors or something like that. No, no, it is tensors only, but you can the background can be Theano or it can be tensor, Jax or ONX, OpenVINO like that. That's what I said. The frameworks can be.
[09:38:17] So compatibility, we can say RAM. So the compatibility is more compared to PyTorch. You cannot deploy it to the Keras, but Keras can be deployed into the PyTorch if you have any model integration. I've got it at the end. Yeah. OK. So let us see technically. It was AMA 26.
[09:38:44] We'll take the classical data, that is iData only, to make you understand. And then we can take, finally, once you recover these three things, and then we'll go with, for example, any classification. You need CNN also, I'll write it down. Before that, first, let us understand, basically, how we write a sequential API and the functional API, what are the differences. And then time permits, I'll show you if you ask anything, like any, for example,
[09:39:10] For example, any classification of the image you want me to write down, I'll write out the code so they can see. Okay. So first let us import all the required libraries from sklearn.datasets import iris train display. Now, I don't need this classifier. So from sklearn.preprocessing,
[09:39:26] import standard scaler and then we can import tensorflow as tf then from keras.models import we'll talk about sequential and
[09:39:40] We need a layers, Keras.layers import. I'm going to use a dense connectivity and I can use input also. And then from Keras,
[09:39:58] I use utils to import 200s for categorical. Okay, so these are the inputs. Iris is equal to, how do we write Iris? So what would be the density?
[09:40:14] Dense in the sense connectivity. I'll explain. Just give me a minute. How dense works I'll explain. There is a question. Sir, how output neuron gets its class identity?
[09:40:30] Is there any redundancy among output neurons? No redundancy, Rakesh. Actually, that depends upon the activation function. So we'll see what is activation function.
[09:40:45] First of all, load iris. Let us define what is x. x is iris.data. We can write it in different data. And y is iris of target.
[09:41:03] Now, if you look into the y, how is the y? 0, 1, 2, right? Now, remember, when you are writing any model, for example, any architecture, sequential architecture or functional architecture,
[09:41:21] architecture or it can be model subclassing Keras need to be converted that into that categorical that means if you have a binary output is bound a binary no need to apply the two categorical okay it is like label encoding we use right similar we are going
[09:41:41] going to, for example, output is binary, binary in the sense zero or one, no need to change. You can keep it as is. But when it comes to if the output is more than two, there is multi-class classification, zero, one, two, something. Why
[09:42:07] because here we know that one had encoder, right? One had encoder in the sense, first of all, zero, how do you mention zero, zero, zero, zero, zero, one, zero, one, zero, something like that, correct? So why? Because here, end of the day, when it comes to the output, we are defining three outputs, correct? So in the sequential API, or it can be functional API,
[09:42:34] or it can be model subclassing, output will be three neurons. So when we have a binary, binary means only one neuron can do the job by using a sigmoid function, whether it is greater than 0.5, belongs to one class, less than 0.5, one class. When you have three neurons and the three outputs are there, one neuron cannot classify, right? So that is the reason we are going to have a three. So when you have a three, here we need to convert that into two categorical, remember.
[09:43:01] Okay, so what is two categorical? I'll show you. For example, now we got the y value, right? So when you look into the y, you see something like this. Now I'll say y is equal to underscore categorical of y. Now I'll print y value. So it is like one-hot encoding, it is converting, right? So for zero, it is taking one, zero, zero. And for one, it is taking zero,
[09:43:23] zero, for two it is getting zero zero one. So this format is needed to predict the output. So when it is needed, if the output is more than two, means if it is not a binary, then we need to do it. This step is needed. If it is binary, this step is not needed. So let me write down here. Binary classification, no need
[09:43:42] this step, right? Okay, done. Once it is done, we got the value of y that is converted into one hard input in time. Now we need to split the data. How do you split? X underscore train, x underscore test, y underscore train, y underscore test is equal
[09:44:03] train underscore test underscore split. So we are going to have X and Y, test size 0.2, and make it properly, okay? Now, remember whenever you are writing a Keras or TensorFlow or PyTorch or anything,
[09:44:30] Standardization is important, right? So that is optimization, what do you call? Either if you have an image, pixels be 0 to 255, we need to convert between 0 to 1. If you have a numerical value, for example, in the Iris data, we have 0, 5.2, 5.3, like that, right? So we want to bring them to the same scale. So for that, we are going to use the standard scalar, okay?
[09:44:57] So yeah, Duryodhana, go ahead. What's the question? Why is it not required for the binary? Can you please explain? Binary have only one neuron can decide, right Duryodhana? One neuron sigmoid function, if you take, one neuron can decide whether it belongs to class A or class B. So if you have a multiclass classification, single neuron cannot take it up, right? So that is the reason the presentation of that neuron
[09:45:26] they kept it as a one-hot encoding output. So there we can see the probabilities are highest probability whatever it is having. For example, out of three, one is highest probability it is having. For example, think like this setosa, this verzenica veriposa, whichever is having highest probability, that neuron will be given the output, right? So that is the reason it expects the same kind of output format. And if you have a multiclass, you have to give like this. For a single output neuron, you can, no need to convert that into categorical.
[09:45:48] Hope it is clear. Then scalar, we create a standard scalar, and then you can convert that into, so for every deep neural network models, or DL models, we need to apply the scaling techniques that is compulsory. So that is where we are applying the standard scalar, and this you know very well, right?
[09:46:05] need to define the model. So I said the first one as when you look into this, how do you build the neural networks? First of all, linear stack of layers, very simple, single input, single output, create by
[09:46:21] are implementing now this architecture right so input how many neurons we have four as four classes then the first hidden layer eight neurons second is ten third is ten and the final output layer is how many neurons we have three neurons correct so let us
[09:46:36] implement this so first of all we need to define the model model is equal we say sequential okay done after that i need to add the so model dot add now i need to
[09:46:53] we call it as a dense. So what is the purpose of the dense? Dense is going to provide the connectivity to one layer to another layer. Now tell me here, this four neurons are connected to how many neurons? Eight neurons, correct?
[09:47:11] So then take the eight neuron first, which is the second hidden. Then we'll write input underscore dimension is equal. Input, how many neurons we have? Four. And then I can write the activation function as a relu.
[09:47:28] Now, let us understand this step first, what we are doing. We said, take the first, we define the model. In the model, we are adding 8 to 4, that means we establish the connection between these two. Correct?
[09:47:50] So we are saying that these eight hidden neurons are connected to this one. In between there, there is an activation function. So which activation function I'm using? Relu. So what the activation function is going to do? Relu is nothing but it is going to take the activation function. Relu is going to take
[09:48:04] 0 to max that means let me explain you okay for example I have two neurons okay so generally what happens here this neuron is connected to this one this neuron is connected to
[09:48:22] this one here we are going to get a z correct so in this one we are going to have a sum and then the activation correct so what do you mean by that sum and activation so for example here this we got 0.1 and we got
[09:48:42] 0.2 and here inputs are let us say 1 and 2. So how do we get the z? We know that this is the w1, this is w2, this is x1, this is x2. So we write w1 times of x1 plus w2 times of x2 plus some bias.
[09:49:04] correct so when you multiply what you are getting now w1 is 0.1 times of x1 is 1 plus 0.2 times of for example x2 is 2 plus biases for example 0.2 so when you add sum up we get 0.1 times of 1 is 0.1 0.4 0.1 0.4 0.2 right how much we got
[09:49:29] So now we need to apply this to the activation function. So when you say this one, here we are going to have a z with activation function. So for example, if I'm using sigmoid, how do you get 1 over e to the power of negative 0.7? So which is going to give you some value. That is, it belongs to, for example, it is greater than 0.5.
[09:49:58] we say belongs to class one, and if it is less than 0.5, we say belongs to class two. So that is where we are going to have an activation function. So now coming to the relu function, what it is going to do, zero to max. That means if it is 0.7, it is greater than zero, right? So what is the output? Output will be 0.7. So for example, if you got negative one, so relu of negative one will be, what is the value
[09:50:26] less than zero, right? So the value will be zero. So whatever the number you're getting, that number will be coming, giving relu. So relu zero comma max. This is a function, okay? So I'm using here, which function I'm using? Relu. So it is going to take the max value from zero to max, okay? So input dimension in the sense, input how many neurons we are connecting to the eight. This is done. First layer is done. Now let us go to the second layer. So now this eight layer,
[09:50:52] need to add to which one? This eight layer, we need to add to which one? The 10th one we need to add, correct? So how do we add? So we say that model.add very simple, dense. Okay, so next layer, how many neurons we have? 10 neurons we have, correct? And what is the activation function? Is really done, third layer also done. Next we'll go with the fourth layer, that is 10, then activation.
[09:51:12] The activation is relu. Then finally we have model.add dense. How many neurons we have? Three. Now here the activation. What is the activation here? Output, right? Output we need to hit softmax. Why? Because we have how many classes? Three classes.
[09:51:30] Let me tell you here, if the output is only two, that is the binary, so which activation function we use? Sigma. So if it is have more than three, anything extra more than two, we call it as a multi-class, right? Multi-class in the
[09:51:51] which function we use? Saftmax. For example, if it is a regression, then they're going to use linear. These are the three functions. Any class will become either binary
[09:52:16] or multi-class if you go with the regression linear only right so anyone we can use yeah Ram tell me what's the question? permutations and combinations can we use their activation functions for example first one we use relu second probably I can use something different one
[09:52:44] Like that. No problem. But is there any impact on the outcome? Definitely. That depends upon the kind of problem statement you are solving. So nobody can generalize that. You have to use relu, sigma.soft. My question is, for example, there are three to four layers out there. I applied layers with relu. And probably I want to use something different activation
[09:53:17] function. That's what I mean to say here. That's what I'm saying, Rama. That depends upon your problem statement and output. If you want to have a single function or multi, if you're giving multi and you're getting good one, good results, you can go with that. There's no limitations. Understood? Okay. Thanks. Thanks. Yeah. Next, what is the question? What is the third one? I just missed it. Third one.
[09:53:51] This regression event. What is the question, Avik? Can you just repeat the question? So there is, for binary, it's sigmoid. For multiclass, it's softmax. What is the password? Regression. If you have a regression problem, it is these two classifications, right? Regression, you're going to have a linear. OK? And Rajnikanth says that how do we arrive at 10, 10 euro for next layer? This is just randomly we took it.
[09:54:40] There is no theory behind that, okay? You can take five, five, six, six, depends upon your problem statement, you can take it, okay? And of the resources also. Thank you, sir. Yeah. Noor Fatima, go ahead with your question. I have a very similar question. Why did we start with four, eight, 10, 10? Four is the input, right, Noor Fatima? In Iris data sample, how many classes, four features are there, right? So four features, that is the reason we started with four. It depends upon like, for example,
[09:55:33] if you have good resources, GPU and everything, you can increase it. Okay? So there is no thumb rule that why we are taking this much. You can take any four, four also, you can take it. But end of the day, accuracy is the main thing, like how the prediction is going on. Okay, next one, Avik is done. Ashok, yeah, go ahead with your question. Sir, can you open your code, sir? My question is on the chain. Sir, here in the model definition, right? We added multiple layers here. So here the order is important, right sir? Order is important in the sense? Adding the layer, dense of 8 one thing, dense of 10 is second one, third one is dense of 10. So if we flip the order meaning,
[09:56:28] it is 10 let us say third one is 15 so if we change the order it will impact or how it will? So you mean to say that so for example according to your architecture okay here what you have 8 you have right so you have to follow this order for example if you are connecting this to 10 so this first hidden layer becomes 10 neurons yes sir so according to the order you are adding architecture will be there Okay, tightly bound. It is a stack of layers, we call it, right? Okay, thank you. Okay, so I'll do one thing. I'll show you visualization how this stack of layers is built, okay? So before that, model.summary, you build the model. And if you want to see the summary, we got how many parameters
[09:57:26] You might have seen when they are building large language models, they are seeing 1 billion parameters, 2 billion parameters, 27 billion parameters, right? So as the number of parameters are increasing, the model capability is increasing, that we know very well, correct? If you take a 3 billion parameter model, any OLAMA, and if you take 30 billion parameter model with OLAMA only, so there's a lot of difference because the thinking process of the model changes everything, correct? So that is we call it as a parameters. Parameters means how many neurons you are training on, correct? So here we got 273 neurons. So first layer we got 40 neurons, second 90, the number of parameters, fourth one we got 110. How do we got these parameters? Okay, let me explain you. For example, first we got how many? They said 40, right? So first we got 40. Next?
[09:58:17] 90, 110. 90, 110. 23. Okay, how do we got? So, for example, think like how many neurons we have first here? Four neurons, correct? So, four neurons are connecting with eight. So, this one is connecting with eight. This is connecting with eight. This is connecting with eight. This is connecting. So, totally how many connections are establishing here? Four multiplied with eight, 32. So 32 plus, these 32 neurons are connected with how many neurons here? 8, correct? So 32 plus 8 means how much we are getting? 40. 40, got it. Now let us go to the second one. 8 neurons, right? 8, 10. So first one, how many? 8 times 10, 80. 80 plus how many neurons are connected? 10.
[09:59:09] 20 we got it correct then that's plus 8 plus 10 i didn't get actually this 8 is the neurons we need to add it right this number of connections plus neurons how many outputs we are getting correct okay so now so see this first one 8 getting one output we are getting our next output so how many outputs we are getting now eight outputs so these 32 connections plus eight outputs that is 40 here 8 tens are 80, plus how many outputs are getting? 10. 80 plus 10, 90. Now 10 tens are 100, plus how many outputs again? Plus 10. Then 110, correct? Now finally, 10 threes are 30, plus how many? 3. So 33, correct? So total 273 parameters, understood everyone?
[10:00:00] Yes, yes. Yes, Sunil. Have a question or? I understand. No, I understand. Just. Okay. Perfect. Okay. So now we got 273 parameters. Perfect. So next is like we have a question that really the stack of layers, how it look like. The total nubble parameters are same as input, is it because of the less data? Yes, Rajni. Okay. Purandre, go ahead. Thanks, sir. Yes, sir. Sir, I didn't get one parameter for each node we have considered. So that parameter, so I didn't get
[10:01:19] that one means which one you didn't get eight eight we have added means in the first layer we had 32 plus eight so those eight you mentioned that since we have eight nodes we are adding it so yeah one parameter for every node yes so that parameter is what that I didn't get it okay so you people have taken the neural networks right yeah yeah Okay. In neural networks, for example, if you have like this, generally these two will connect. Okay. So how many connections are established now? Two, correct? Yes. Then get some output, we call it ZR naught. Right, right. So we have how many parameters now? Two plus one. Okay, okay. Great. Yeah, got it. Yeah. Great. Now again, for this
[10:02:42] one two plus three how much yeah three six six total six what I'm saying is one two three four plus this two is coming to six or not that's what I'm trying to explain yeah yeah thanks these two are biased right they are not biased it and their ass is inside the with the best complete Z values Z values w1 times of x1 plus w2 times x2 plus bias correct Yeah, but like weights and bias, we learn. Combination, weights and bias, one value we are getting. Yeah, so these four weights plus two bias, right? Yes. Yeah. So our parameters are the summation of the weights and biases because they are CS Rupesh, yes. Okay, great. So now I'll jump into closer. Okay, I'll do one thing. I'll try to show you visualization, PIP, install. There is a library Keras Visualizer. So I can say from Keras Visualizer import
[10:03:46] visualizer and visualizer the model I named it equal to test and format Fine. So this is our isolation, correct? So first we started with the input hidden layer with eight, 10 neurons and 10 neurons and then? the activation function we got is the output. This is the inputs, green color outputs, and these are the three header layers which is generated through the model. Now the stack is correct or not? 8, 10, 10. Whatever the way we are adding
[10:05:26] Correct? Okay, perfect. Jitender, you have a question? No, no, yeah, thanks. Okay, perfect. Now we got the model. So if you look into this, how do you build it now in the building? First of all, we define the architecture. This is what we defined. Then we need to compile the model, okay? So let us go to the next step. So how do you compile the model? So we say model.compile. Here we need to mention loss is categorical cross entropy, optimizer function, and matrix is accuracy. What is the loss here? Loss, either we can go over binary cross entropy if it is a binary classification, or it is a multiclass, we have to go with the categorical cross entropy. For example, regression, we are going to take a mean square error. MSC, we can take it.
