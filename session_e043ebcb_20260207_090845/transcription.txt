# Live Transcription Session: session_e043ebcb_20260207_090845
# Started: 2026-02-07T09:08:45.995898
# Language: en
# Model: medium
# Accumulation Duration: 5.0s
# Save Audio: No
# ============================================================

[09:09:13] I think it is 9 or 8, I think. Can start, right? Shall we start?
[09:09:26] Yes, yes, please. OK, great. OK, so let us start the session. Good morning, everyone. Hope everybody is doing good.
[09:09:40] Today we'll start with Keras framework, another deep learning framework. We'll discuss practically how do we implement Keras and in real time when you are deploying your deep
[09:09:52] learning models. How do you make that Keras available in the train model? So I won't
[09:10:06] the technical implementations and I'll use the whiteboard again as usual. So let us start with what is first Keras. What do you know about the Keras and why do we use
[09:10:21] here as we'll see. So you know, what is a Jup neural network, right? So when we thought of classical machine learning, classical machine learning have a limitation that it cannot handle
[09:10:37] huge amount of the data, and it cannot take classical, you know, sorry, the structured data and structured data. So to come out of the problem, they came across with deep neural network, which is a mimic of a human brain where we talk about the
[09:10:57] perceptron so the first model is perceptron model then we came up with multi-layer perceptron model MLP then we got the deep neural networks again in the deep neural networks we got about convolution neural networks for image and the recurrent neural network for the text processing LSTM like the
[09:11:18] different models has been developed. Now, to implement these models, apart from Python, we need a framework so that we can build these models. So to build these models, they came up with the PyTorch, the JAX, you have TensorFlow, then we got the Keras. So why
[09:11:35] with the nowadays people are more towards the Keras, we'll see. So basically you start with Keras is a deep neural network framework we can say, which is written completely in Python. Basically it is designed for fast experimentation
[09:11:51] Deep learning models. So originally, it was created by Charlotte, who is a part of a one IRO research project. So there has been grown into like one of the most widely used and adapted
[09:12:04] deep learning frameworks with over 300, so 3 million developers in the worldwide. Okay. Okay. So why we use Keras generally? You can say
[09:12:15] that it is a Python native. Then it has a modular design.
[09:12:25] Then it is multi backend. And then we have around three
[09:12:37] and plus developer communities there. So this is like, you know, basically why do we use Keras framework?
[09:12:49] And in Keras, we have three different kinds of models. So before that, let me explain you
[09:12:57] Oh.
[09:13:07] get us one point.
[09:13:18] which is a standard model. Then in 2019 they came up with Keras 2.x which is
[09:13:31] integrated into TensorFlow. You know TensorFlow is a Google framework, right? So generally we used to use TensorFlow, but now they integrated Keras into
[09:13:46] TensorFlow using Keras and TensorFlow both are the same. Backend will be TensorFlow only, but the wrapper is the Keras, which will make it easy for that. Then in 2023, we got Keras three
[09:14:02] Now we are with 25, we have Keras 3.13 something like that we have. So what is the difference here?
[09:14:19] and it is supporting only two kinds of Thano and the TensorFlow backends. Then 2.x onwards, they integrated into TensorFlow. So when you install TensorFlow, automatically Keras will be installed and through Keras,
[09:14:41] Keras. That means we can access Keras through TensorFlow object. And it became the official and high-level API of Google then. So Google integrated into that. So the Charlotte is one of the employees of Google only. He was
[09:15:04] framework, Keras actually. Then coming to 3.0, which is not only supporting only Theano and TensorFlow, then it is supporting the multi-backend. That multi-backend in the sense, if you are developing a model in Keras, you can deploy using a JAGS, TensorFlow, PyTorch also, OpenVINO is there.
[09:15:31] is where it is. Now, after that, here, 2025, we got as a LiteRT export, we call it. That means it is going to support with ONNX. ONNX in the sense, it is going to support lightweight edge devices. For example, you want to deploy the model into mobile devices, it is possible. And then it has been given the quantization. So nowadays, we are using the term
[09:15:59] quantum computers, right? The quantization in the sense converting the model into the smaller format that also supported in 2025. That means if you build a model in Keras, for example, the model came up with say that 500 MB of the size, right? So we can use quantization with the same capacity, means same kind of output, but the size will be decreased. We'll see that with the practical, okay?
[09:16:22] That is the 2025, we got the latest model. So in the latest 2025, it supports a lot of the framework and it is like industry adapted. Now the question is why we need to use Keras? First thing is we say that it is fast prototyping. Suppose if you want to build any POC kind of thing immediately, so that is very fast we can build through.
[09:16:43] second thing is it has we call it as a best-in-class performance so when you are deploying the model the model performance is better that means when you are deploying on to the edge devices on to the like you know GPU CPUs like that and it support full architecture support full architecture support in the sense you know about
[09:17:06] So for example, we know convolution neural networks, any architecture, it's supposed like that. So most of the deep learning architectures starting from convolution neural networks, recurrent neural networks, transformers, and you have hybrid networks, then we have GANs, Generative Adversary Networks, all of the architectures they'll support.
[09:17:28] And next one, fourth one, we say that as a performance, it supports seamless hardware. So what do you mean by seamless hardware? That means it runs on CPU, it runs on GPU, it runs on TPU without any code changes and scales from automatically when you deploy the model, it scales from laptop prototyping to data center scale.
[09:17:44] distributed training happens okay and next one is we can talk about the portability so portability in the sense we can once you write the code in Keras you can import export that particular module as a
[09:18:09] PyTorch module you can export. As a TensorFlow model, you can save. As a JAX function, you can save it. Or you can use the TF Lite format so that you can deploy onto the mobile and edge devices. This is the next. Another one important thing is as it is an open source.
[09:18:35] Okay, and you can see the community also, right? So we have around 3 million community for Keras. Okay, so now, once you understand why we need Keras, from these features, we can understand that Keras is a growing framework for any deep learning models, architectures, we can say.
[09:19:01] if you are building a conversion neural networks or if you are building recurrent neural networks or GANs or anything, we understand that Keras is one of the best framework due to these properties, like six properties what I mentioned. Easily you can write the code. You can see, you can write a stack of layers very easily and we see practically how do we implement all those things. I'll stop here for
[09:19:19] Any questions? Okay, good. Now, we got the importance of the Keras framework. And then, for example, if you are building any architecture in
[09:19:34] how many ways we can build the Keras models. So to build the Keras models, we have three API styles. So first thing is we call it as a sequential API.
[09:19:46] Second, we'll talk about functional API. Then third, model.
[09:20:02] subclassing so like when you write for example if you write if i ask you write a program to check given number is a prime or not right
[09:20:20] revenue in Python program. So generally what you write, if I say enter a number, then you take the number, you'll check whether it is less than or equal to one, or you will take the number or divide by itself
[09:20:41] the code. So then some people, what they will do, okay, instead of writing the code for the modularity, they put it in a function saying that it is something like, you know, find prime function, they will write it inside the function, they will give a parameter and they take the parameters, then they'll write the code.
[09:21:07] the third one what he will do he will define a class and here he is going to write the function here there's a class he will write the function and he will call the function here just by passing the number so for a simple to check given number is a prime number in how many ways we have written a different ways are there for example if you consider people
[09:21:44] can write in different way. But basically, if I start, I can say, okay, people, they write a step by step lines they are writing. This is one way. Second is he's defining the function. Third way, he's defining the class. And in one of the, like, you know, another notebook, he's calling that class, the object of the class is calling the function. So similar way, when you're writing a Keras framework, we can define the deep learning architecture in Keras.
[09:22:19] One is a sequential API. That means stack of layers, we can do it. Functional API, we can define as a function. Third one is model subclassing. So we can keep a function, particular function in a class, and then we can import the class. So there are three different ways of writing Keras models. We'll see, we'll start with the first sequential. Okay. So in sequential model, we are going to have first thing is a linear stack of layers.
[09:22:48] So which is very simple. What do you mean by linear stack of layers? So we know that in deep learning, when you're defining, first we have a input layer, right? Which is with some of the parameters we have. Then we have some hidden layers, neural networks. So we have some hidden layers. Then we are going to have finally output layer. So input layer, output layer, then we have some hidden layers. Here we can define
[09:23:14] So first I can define one layer, then I can add to the second layer, then add third layer, fourth layer, fifth layer, then sixth layer like that, okay? And this works for single input, single output only. What do you mean by single input and single output? Single input and single output. For example, if you consider Iris data, Iris data is a single input which consists of four features.
[09:23:39] features, sepal length, sepal width, petal length and petal width. Now when it goes in, what is the prediction? Either it is going to be a setosa or vergenica, that means single problem statement and output also a single only. So either you classify iris setosa or find the house prices or check the given person, given animal is, for example, elephant or something.
[09:23:57] okay so single input single output only right and here we are going to create by stacking layers it by stacking layers one after another go ahead Ashok yes a small question actually
[09:24:18] single input single output I understood what is the other other thing sir other thing is sometimes we can get a two problem statements and waiting in the one output or two output that comes in functional API okay I mean so far we did not see that that's the reason I that's so far we are seeing in class anymore
[09:24:35] learning algorithms, one input and one output only, okay? Today, we'll see two inputs are one input, two output also. Thanks, sir. Thank you. Yeah. Okay, this is best for quick prototypes.
[09:24:52] And if you want to write some simple classifier, then this is the best one. Okay. So this is a sequential model. So what I will do, first of all, I will explain what is a sequential model. Okay.
[09:25:14] So then I'll write down the code and then we'll come back to the functional, then we'll write down the code, then we'll write down the model subclassing. So that way you can understand it one by one. So first let us completely understand what is a sequential model, okay? So now here you see,
[09:25:34] Like in the sequential model, we are going to have a linear stack of layers, single input on single output. And how do you create? Create by stacking the layers. And best for quick prototypes and simple classifier. Now, how do you build that building step? First of all, we need to define architecture.
[09:25:49] Second, compile the model. Third, train. That is nothing but fit the model. And the next one, we evaluate them.
[09:26:06] So first of all, we need to understand, define the model. So I hope you understand like, you know, how do you define the architecture, compile the model, you know.
[09:26:25] how to train the models you have seen and how do we evaluate the model. So then here we have like when you're defining the architecture we are using neural network right. So when you're using neural network generally in neural network we have some of the parameters
[09:26:38] parameters we have, right? So we can say neural network, model, parameters. Okay, so let me first start with architecture parameters.
[09:26:50] Second, training parameters. Third, evaluation parameters.
[09:27:05] So when you're defining any neural network, so generally we are going to have model parameters. So here we have, first of all, number of layers.
[09:27:17] generally we call it as a depth. Second we have neurons per layer.
[09:27:29] So we call it as a width. Then what is a layer connectivity pattern?
[09:27:38] Next, activation function.
[09:27:52] So next, if you have something like a dropout, OK? And then we have batch.
[09:28:06] normalization. This comes into architecture parameters. Coming to the training parameters, we are going to have an optimizer. So in the optimized
[09:28:24] For example, Adam, Stochastic Gradient Distance JD, Adam W, Lion, like different optimizers will be there. Then we are going to have a last function. Inside the training, we need to define this model parameter.
[09:28:41] And then we can define the learning rate. Then we can define how many number of epochs. Then we can define what is the batch size. And then coming to the evaluation, either we can go with the accuracy.
[09:28:59] Then we can go with the confusion matrix. And then we can go with the train, test, validation split. And sometimes we go with the list stopping, and then we go with the cross validation.
[09:29:16] So these are some of the model neural network parameters. So when you talk about these parameters model, you might have seen when they define a convolution neural network or when you define recurrent neural networks, when you define
[09:29:35] any neural network, deep neural network, when you have seen the architectural parameters, architectural parameter in the sense like how many number of layers we need, how many number of neurons we are going to consist of, all those things we call it as architecture. So for example, let us take
[09:30:05] a real example. Let us take Iris data sample, simple. I have Iris data. Iris data is a classification problem, right? So which is going to have multi-class classification. Why? Because the target column consists of Setosa, Virginica, Vericosa, and Setosa, Virginica, Vericosa, right? Three only, correct?
[09:30:30] So now, here input how many features we have. For example, I have one, two, three, four features. That is sepal length, sepal width, petal length, and petal width. Now let us build the architecture. So I'm going to have three hidden layers. For example, which is say I have eight neurons. And then something say 10.
[09:30:55] neurons again ten neurons and finally I'm going to have a three neurons as a output layer so in input layer how many neurons we have four neurons correct that means sepal length is going to have one neuron sepal width one neuron petal length and petal width then I have defined eight neurons and ten neurons ten neurons and finally output layer consists of three
[09:31:24] So I'm going to use a softmax. From that, I can define whichever is having the highest probability. That will be my target column. Correct? So now, if you see the architecture parameter, here we say number of layers is the depth. Now, how many layers we have now? Input layer, three hidden layers, and output layer. Totally, this is known as a width. Depth, we call it. So how much depth? Then neurons per layer.
[09:31:59] So, what is the highest width now? For every layer, we have how many here? I got 8, 10, 10. So, highest layer neuron is 10. So, what is the width now? 10 neurons. So, then connectivity pattern, how I'm going to connect and what kind of activation functions we are using. If I'm using any dropout, I can use the dropout here. Otherwise, I can go with the batch navigation also, okay? So, now, then we'll go with the optimizer. So, before that, I want
[09:32:21] So generally when you look at the neural network, how is the neural network? This is sepal length, sepal width, petal length, and petal length. Now this connect to
[09:32:31] like this.
[09:32:42] So every neuron will connect with another neuron. Yes or no?
[09:32:54] Before jumping into the coding part, do you have any questions?
[09:33:10] Yes, I should go ahead. Yes sir, one question sir, I mean generic only. Generally sir, this output layer I am talking about. Output layer, let us take, right now we have three different
[09:33:27] In our case, we have three different things. That's why we are taking two neurons. Why don't we use only one? As neuron contains values from 0 to 255, why don't you use single neuron?
[09:33:47] 0 to 255. Yeah, each neuron can have a value from 0 to 255, right? Who said? That is my understanding, sir. No. No, no, no. Don't put any value for a neuron, okay? Okay, okay. Fixed cell value is 0 to 255, sir.
[09:34:11] So when you're taking image, pixel value but again we optimize that will become 0 to 1 only. And one more thing is that in the hidden layer thing right, so I'm talking about from the convolution layer point of view, we have some input let us say some x, then we made some 2x, then
[09:34:34] we made again. Next is previous into multiplied with 2x like that we are increasing. Is there any particular order like we have to increase or we can maintain save number? No, nothing. We don't have any thumb rule or any order. This is completely hit and run. So remember, complete machine learning is hit and run only. Okay, so there is
[09:34:59] to get this many neurons or this many. It is completely depends upon the experience you can define and after the output you are looking at, you can make number of layers you can increase or number of neurons you can increase like that. Okay. Thanks sir. Thank you. Sir, one more question. Instead of using all these hidden layers,
[09:35:26] Why don't we go for MLPs or multilayer perceptrons? Multilayer perceptron is a different architecture and we are talking about deep neural networks, right? So deep neural networks is one step ahead of the multi-neural networks. So when you combine the neural networks, that's where you're getting the deep neural networks. Again, going back to multi-neural networks doesn't have
[09:35:58] I have no idea. That's why I'm asking you. So here, actually, first we started with Perceptron model. It was only able to classify linear problems. Nonlinear, it was unable to. Then we came up with multi-layer Perceptron, introduced two layers. Then the thinking process increased with deep network. So that is a step ahead. So the combination is actually, we can say that Perceptron
[09:36:41] to three, to four, to four, something like that, right? The multiples. So this is, we can say, think like if you're taking a part is multi-layer perceptron only, the combination of multi-layer perceptron is the deep neural networks. Yeah. Rakesh, thank you. Yeah. Sir, I don't know if I'm jumping ahead, but are there any rules or best practices in terms of which activation function to choose for a classification versus a regression problem?
[09:37:43] Yeah, yeah, we'll talk about that now when I'm writing the code, but I will do that. Yeah. Yeah. Okay. I think, who is there? Somebody raised their hand and he says. Yes, sir. I'm Ram, actually. So, with respect to this, it's purely sit on top of the tensor, I mean tensor, or it will also have their own framework because in your site. Okay. In your slide you have been written that it is either tensors or something like that. No, no, it is tensors only, but you can the background can be Theano or it can be tensor, Jax or ONX, OpenVINO like that. That's what I said. The frameworks can be.
[09:38:17] So compatibility, we can say RAM. So the compatibility is more compared to PyTorch. You cannot deploy it to the Keras, but Keras can be deployed into the PyTorch if you have any model integration. I've got it at the end. Yeah. OK. So let us see technically. It was AMA 26.
[09:38:44] We'll take the classical data, that is iData only, to make you understand. And then we can take, finally, once you recover these three things, and then we'll go with, for example, any classification. You need CNN also, I'll write it down. Before that, first, let us understand, basically, how we write a sequential API and the functional API, what are the differences. And then time permits, I'll show you if you ask anything, like any, for example,
[09:39:10] For example, any classification of the image you want me to write down, I'll write out the code so they can see. Okay. So first let us import all the required libraries from sklearn.datasets import iris train display. Now, I don't need this classifier. So from sklearn.preprocessing,
[09:39:26] import standard scaler and then we can import tensorflow as tf then from keras.models import we'll talk about sequential and
[09:39:40] We need a layers, Keras.layers import. I'm going to use a dense connectivity and I can use input also. And then from Keras,
[09:39:58] I use utils to import 200s for categorical. Okay, so these are the inputs. Iris is equal to, how do we write Iris? So what would be the density?
[09:40:14] Dense in the sense connectivity. I'll explain. Just give me a minute. How dense works I'll explain. There is a question. Sir, how output neuron gets its class identity?
[09:40:30] Is there any redundancy among output neurons? No redundancy, Rakesh. Actually, that depends upon the activation function. So we'll see what is activation function.
[09:40:45] First of all, load iris. Let us define what is x. x is iris.data. We can write it in different data. And y is iris of target.
[09:41:03] Now, if you look into the y, how is the y? 0, 1, 2, right? Now, remember, when you are writing any model, for example, any architecture, sequential architecture or functional architecture,
[09:41:21] architecture or it can be model subclassing Keras need to be converted that into that categorical that means if you have a binary output is bound a binary no need to apply the two categorical okay it is like label encoding we use right similar we are going
[09:41:41] going to, for example, output is binary, binary in the sense zero or one, no need to change. You can keep it as is. But when it comes to if the output is more than two, there is multi-class classification, zero, one, two, something. Why
[09:42:07] because here we know that one had encoder, right? One had encoder in the sense, first of all, zero, how do you mention zero, zero, zero, zero, zero, one, zero, one, zero, something like that, correct? So why? Because here, end of the day, when it comes to the output, we are defining three outputs, correct? So in the sequential API, or it can be functional API,
[09:42:34] or it can be model subclassing, output will be three neurons. So when we have a binary, binary means only one neuron can do the job by using a sigmoid function, whether it is greater than 0.5, belongs to one class, less than 0.5, one class. When you have three neurons and the three outputs are there, one neuron cannot classify, right? So that is the reason we are going to have a three. So when you have a three, here we need to convert that into two categorical, remember.
[09:43:01] Okay, so what is two categorical? I'll show you. For example, now we got the y value, right? So when you look into the y, you see something like this. Now I'll say y is equal to underscore categorical of y. Now I'll print y value. So it is like one-hot encoding, it is converting, right? So for zero, it is taking one, zero, zero. And for one, it is taking zero,
[09:43:23] zero, for two it is getting zero zero one. So this format is needed to predict the output. So when it is needed, if the output is more than two, means if it is not a binary, then we need to do it. This step is needed. If it is binary, this step is not needed. So let me write down here. Binary classification, no need
[09:43:42] this step, right? Okay, done. Once it is done, we got the value of y that is converted into one hard input in time. Now we need to split the data. How do you split? X underscore train, x underscore test, y underscore train, y underscore test is equal
[09:44:03] train underscore test underscore split. So we are going to have X and Y, test size 0.2, and make it properly, okay? Now, remember whenever you are writing a Keras or TensorFlow or PyTorch or anything,
[09:44:30] Standardization is important, right? So that is optimization, what do you call? Either if you have an image, pixels be 0 to 255, we need to convert between 0 to 1. If you have a numerical value, for example, in the Iris data, we have 0, 5.2, 5.3, like that, right? So we want to bring them to the same scale. So for that, we are going to use the standard scalar, okay?
[09:44:57] So yeah, Duryodhana, go ahead. What's the question? Why is it not required for the binary? Can you please explain? Binary have only one neuron can decide, right Duryodhana? One neuron sigmoid function, if you take, one neuron can decide whether it belongs to class A or class B. So if you have a multiclass classification, single neuron cannot take it up, right? So that is the reason the presentation of that neuron
[09:45:26] they kept it as a one-hot encoding output. So there we can see the probabilities are highest probability whatever it is having. For example, out of three, one is highest probability it is having. For example, think like this setosa, this verzenica veriposa, whichever is having highest probability, that neuron will be given the output, right? So that is the reason it expects the same kind of output format. And if you have a multiclass, you have to give like this. For a single output neuron, you can, no need to convert that into categorical.
[09:45:48] Hope it is clear. Then scalar, we create a standard scalar, and then you can convert that into, so for every deep neural network models, or DL models, we need to apply the scaling techniques that is compulsory. So that is where we are applying the standard scalar, and this you know very well, right?
[09:46:05] need to define the model. So I said the first one as when you look into this, how do you build the neural networks? First of all, linear stack of layers, very simple, single input, single output, create by
[09:46:21] are implementing now this architecture right so input how many neurons we have four as four classes then the first hidden layer eight neurons second is ten third is ten and the final output layer is how many neurons we have three neurons correct so let us
[09:46:36] implement this so first of all we need to define the model model is equal we say sequential okay done after that i need to add the so model dot add now i need to
[09:46:53] we call it as a dense. So what is the purpose of the dense? Dense is going to provide the connectivity to one layer to another layer. Now tell me here, this four neurons are connected to how many neurons? Eight neurons, correct?
[09:47:11] So then take the eight neuron first, which is the second hidden. Then we'll write input underscore dimension is equal. Input, how many neurons we have? Four. And then I can write the activation function as a relu.
[09:47:28] Now, let us understand this step first, what we are doing. We said, take the first, we define the model. In the model, we are adding 8 to 4, that means we establish the connection between these two. Correct?
[09:47:50] So we are saying that these eight hidden neurons are connected to this one. In between there, there is an activation function. So which activation function I'm using? Relu. So what the activation function is going to do? Relu is nothing but it is going to take the activation function. Relu is going to take
[09:48:04] 0 to max that means let me explain you okay for example I have two neurons okay so generally what happens here this neuron is connected to this one this neuron is connected to
[09:48:22] this one here we are going to get a z correct so in this one we are going to have a sum and then the activation correct so what do you mean by that sum and activation so for example here this we got 0.1 and we got
[09:48:42] 0.2 and here inputs are let us say 1 and 2. So how do we get the z? We know that this is the w1, this is w2, this is x1, this is x2. So we write w1 times of x1 plus w2 times of x2 plus some bias.
[09:49:04] correct so when you multiply what you are getting now w1 is 0.1 times of x1 is 1 plus 0.2 times of for example x2 is 2 plus biases for example 0.2 so when you add sum up we get 0.1 times of 1 is 0.1 0.4 0.1 0.4 0.2 right how much we got
[09:49:29] So now we need to apply this to the activation function. So when you say this one, here we are going to have a z with activation function. So for example, if I'm using sigmoid, how do you get 1 over e to the power of negative 0.7? So which is going to give you some value. That is, it belongs to, for example, it is greater than 0.5.
[09:49:58] we say belongs to class one, and if it is less than 0.5, we say belongs to class two. So that is where we are going to have an activation function. So now coming to the relu function, what it is going to do, zero to max. That means if it is 0.7, it is greater than zero, right? So what is the output? Output will be 0.7. So for example, if you got negative one, so relu of negative one will be, what is the value
[09:50:26] less than zero, right? So the value will be zero. So whatever the number you're getting, that number will be coming, giving relu. So relu zero comma max. This is a function, okay? So I'm using here, which function I'm using? Relu. So it is going to take the max value from zero to max, okay? So input dimension in the sense, input how many neurons we are connecting to the eight. This is done. First layer is done. Now let us go to the second layer. So now this eight layer,
[09:50:52] need to add to which one? This eight layer, we need to add to which one? The 10th one we need to add, correct? So how do we add? So we say that model.add very simple, dense. Okay, so next layer, how many neurons we have? 10 neurons we have, correct? And what is the activation function? Is really done, third layer also done. Next we'll go with the fourth layer, that is 10, then activation.
[09:51:12] The activation is relu. Then finally we have model.add dense. How many neurons we have? Three. Now here the activation. What is the activation here? Output, right? Output we need to hit softmax. Why? Because we have how many classes? Three classes.
[09:51:30] Let me tell you here, if the output is only two, that is the binary, so which activation function we use? Sigma. So if it is have more than three, anything extra more than two, we call it as a multi-class, right? Multi-class in the
[09:51:51] which function we use? Saftmax. For example, if it is a regression, then they're going to use linear. These are the three functions. Any class will become either binary
[09:52:16] or multi-class if you go with the regression linear only right so anyone we can use yeah Ram tell me what's the question? permutations and combinations can we use their activation functions for example first one we use relu second probably I can use something different one
[09:52:44] Like that. No problem. But is there any impact on the outcome? Definitely. That depends upon the kind of problem statement you are solving. So nobody can generalize that. You have to use relu, sigma.soft. My question is, for example, there are three to four layers out there. I applied layers with relu. And probably I want to use something different activation
[09:53:17] function. That's what I mean to say here. That's what I'm saying, Rama. That depends upon your problem statement and output. If you want to have a single function or multi, if you're giving multi and you're getting good one, good results, you can go with that. There's no limitations. Understood? Okay. Thanks. Thanks. Yeah. Next, what is the question? What is the third one? I just missed it. Third one.
[09:53:51] This regression event. What is the question, Avik? Can you just repeat the question? So there is, for binary, it's sigmoid. For multiclass, it's softmax. What is the password? Regression. If you have a regression problem, it is these two classifications, right? Regression, you're going to have a linear. OK? And Rajnikanth says that how do we arrive at 10, 10 euro for next layer? This is just randomly we took it.
[09:54:40] There is no theory behind that, okay? You can take five, five, six, six, depends upon your problem statement, you can take it, okay? And of the resources also. Thank you, sir. Yeah. Noor Fatima, go ahead with your question. I have a very similar question. Why did we start with four, eight, 10, 10? Four is the input, right, Noor Fatima? In Iris data sample, how many classes, four features are there, right? So four features, that is the reason we started with four. It depends upon like, for example,
[09:55:33] if you have good resources, GPU and everything, you can increase it. Okay? So there is no thumb rule that why we are taking this much. You can take any four, four also, you can take it. But end of the day, accuracy is the main thing, like how the prediction is going on. Okay, next one, Avik is done. Ashok, yeah, go ahead with your question. Sir, can you open your code, sir? My question is on the chain. Sir, here in the model definition, right? We added multiple layers here. So here the order is important, right sir? Order is important in the sense? Adding the layer, dense of 8 one thing, dense of 10 is second one, third one is dense of 10. So if we flip the order meaning,
[09:56:28] it is 10 let us say third one is 15 so if we change the order it will impact or how it will? So you mean to say that so for example according to your architecture okay here what you have 8 you have right so you have to follow this order for example if you are connecting this to 10 so this first hidden layer becomes 10 neurons yes sir so according to the order you are adding architecture will be there Okay, tightly bound. It is a stack of layers, we call it, right? Okay, thank you. Okay, so I'll do one thing. I'll show you visualization how this stack of layers is built, okay? So before that, model.summary, you build the model. And if you want to see the summary, we got how many parameters
[09:57:26] You might have seen when they are building large language models, they are seeing 1 billion parameters, 2 billion parameters, 27 billion parameters, right? So as the number of parameters are increasing, the model capability is increasing, that we know very well, correct? If you take a 3 billion parameter model, any OLAMA, and if you take 30 billion parameter model with OLAMA only, so there's a lot of difference because the thinking process of the model changes everything, correct? So that is we call it as a parameters. Parameters means how many neurons you are training on, correct? So here we got 273 neurons. So first layer we got 40 neurons, second 90, the number of parameters, fourth one we got 110. How do we got these parameters? Okay, let me explain you. For example, first we got how many? They said 40, right? So first we got 40. Next?
[09:58:17] 90, 110. 90, 110. 23. Okay, how do we got? So, for example, think like how many neurons we have first here? Four neurons, correct? So, four neurons are connecting with eight. So, this one is connecting with eight. This is connecting with eight. This is connecting with eight. This is connecting. So, totally how many connections are establishing here? Four multiplied with eight, 32. So 32 plus, these 32 neurons are connected with how many neurons here? 8, correct? So 32 plus 8 means how much we are getting? 40. 40, got it. Now let us go to the second one. 8 neurons, right? 8, 10. So first one, how many? 8 times 10, 80. 80 plus how many neurons are connected? 10.
[09:59:09] 20 we got it correct then that's plus 8 plus 10 i didn't get actually this 8 is the neurons we need to add it right this number of connections plus neurons how many outputs we are getting correct okay so now so see this first one 8 getting one output we are getting our next output so how many outputs we are getting now eight outputs so these 32 connections plus eight outputs that is 40 here 8 tens are 80, plus how many outputs are getting? 10. 80 plus 10, 90. Now 10 tens are 100, plus how many outputs again? Plus 10. Then 110, correct? Now finally, 10 threes are 30, plus how many? 3. So 33, correct? So total 273 parameters, understood everyone?
[10:00:00] Yes, yes. Yes, Sunil. Have a question or? I understand. No, I understand. Just. Okay. Perfect. Okay. So now we got 273 parameters. Perfect. So next is like we have a question that really the stack of layers, how it look like. The total nubble parameters are same as input, is it because of the less data? Yes, Rajni. Okay. Purandre, go ahead. Thanks, sir. Yes, sir. Sir, I didn't get one parameter for each node we have considered. So that parameter, so I didn't get
[10:01:19] that one means which one you didn't get eight eight we have added means in the first layer we had 32 plus eight so those eight you mentioned that since we have eight nodes we are adding it so yeah one parameter for every node yes so that parameter is what that I didn't get it okay so you people have taken the neural networks right yeah yeah Okay. In neural networks, for example, if you have like this, generally these two will connect. Okay. So how many connections are established now? Two, correct? Yes. Then get some output, we call it ZR naught. Right, right. So we have how many parameters now? Two plus one. Okay, okay. Great. Yeah, got it. Yeah. Great. Now again, for this
[10:02:42] one two plus three how much yeah three six six total six what I'm saying is one two three four plus this two is coming to six or not that's what I'm trying to explain yeah yeah thanks these two are biased right they are not biased it and their ass is inside the with the best complete Z values Z values w1 times of x1 plus w2 times x2 plus bias correct Yeah, but like weights and bias, we learn. Combination, weights and bias, one value we are getting. Yeah, so these four weights plus two bias, right? Yes. Yeah. So our parameters are the summation of the weights and biases because they are CS Rupesh, yes. Okay, great. So now I'll jump into closer. Okay, I'll do one thing. I'll try to show you visualization, PIP, install. There is a library Keras Visualizer. So I can say from Keras Visualizer import
[10:03:46] visualizer and visualizer the model I named it equal to test and format Fine. So this is our isolation, correct? So first we started with the input hidden layer with eight, 10 neurons and 10 neurons and then? the activation function we got is the output. This is the inputs, green color outputs, and these are the three header layers which is generated through the model. Now the stack is correct or not? 8, 10, 10. Whatever the way we are adding
[10:05:26] Correct? Okay, perfect. Jitender, you have a question? No, no, yeah, thanks. Okay, perfect. Now we got the model. So if you look into this, how do you build it now in the building? First of all, we define the architecture. This is what we defined. Then we need to compile the model, okay? So let us go to the next step. So how do you compile the model? So we say model.compile. Here we need to mention loss is categorical cross entropy, optimizer function, and matrix is accuracy. What is the loss here? Loss, either we can go over binary cross entropy if it is a binary classification, or it is a multiclass, we have to go with the categorical cross entropy. For example, regression, we are going to take a mean square error. MSC, we can take it.
[10:07:11] that we have different optimizer functions, like we can go with Adam or SGD, or we can go with Adam W or Lion, like different Adam functions are there. If you want, you can check in. For example, there are optimizers. So you can see now I'm using Adam, right? So in Adam class, there's a default learning rate is there. And the weight decay, we have a lot of things, right? So you can take any one. So what are the arguments you have? According to like latest one is optimizer is Adam. I'm just considering Adam only, okay? I can take SGD, I can take any model. Let us compile the model. Yes, Ashok, go ahead. Sir, this is another basic question. Right now we are connecting every node in the current layer to the every other node in the next layer. So somewhere I read like, if we have connected like this, it requires huge memory and things like that. So that is the reason we need to optimize something like that. So my question around that, is it the mandatory that we need to connect everything to all other things in the next layer or there are some ways we can reduce that number of connections? No way it is possible Venkat, but as you said, the stack of layers is different and building the architecture somewhere using is different. and making it as a function to make it faster is different. So the sequential model limitation is when you have less number of neurons, less number of layers, we can go with that.
[10:08:44] So as you said is a memory intensive, then we go with the functional. That is the reason when I started my lecture I said there are three ways to define the architecture. One is sequential API, second is a functional, third is the model subclassing. So once we'll see what is the sequential API and we'll see what is the pros and cons and what is the real time use cases, then we'll move on to the functional. At that time we'll see why it is memory intensive and that's the reason if it is memory intensive we'll go with some other. If everything is good, we might have not gone with functional and model subclassing, right? So defining the architecture is sometimes depending upon the problem statement, some cases are memory intensive, but writing a prototype, it doesn't have any problem, right? So for a prototype, I can go with the sequential API. Production level, I will go with the functional API or model subclassing, okay? Yes, sir, thank you. Okay, so now model compile is done. Then what should we do now? Model.fit. So in the fit, we are going to write generally in classical machine learning. How do we fit? The same thing we do it. Y underscore train. And then we can write a box. This is equal, for example, 100 epochs I can take. And batch size is equal, let us take as a five. Here we have it verbose is equal to zero, for example. So when I write zero, see what happens. That size. X train and Y train. So it's a
[10:09:52] output must have the same there is a problem which output it to it a change something you got categorical then X and Y, okay. So the parameter which we can for matrix is equal to accuracy. So what in all different values can we, we can see like for that particular- If you have a classical machine learning, we go with accuracy. If it is a regression problem, we'll go with a mean square error, right? MSC. That's all. So model.compile Okay, so when it's a model.fait, you don't see what is happening, right? Just execution is going on, correct? So finally it executed, you don't know. So that is where we write verbose is equal to zero. If you write verbose is equal to one, you can see the execution. Okay, how it is executing.
[10:11:03] Now, here if you see, 24 you got it, right? So how do you got 24 here? At a time it is batch as a 24. Because I said batch size is equal to five, means it's going to divide, actually we have totally how many, in Iris data sample, how many we have, tell me? 150, correct? 150 sample, yes or no? Yes, sir. Okay, out of 150, we kept 20% for the testing. Remaining is how much? 120. Yes? Yes. Okay. 120 divided by five, how much will you get? 24, correct? Yes. Yes. So it divided into 24, 24, 24 into five batches. Okay. That's the reason it's a time. And how many epochs I said, a hundred times. So it will take one, it will execute a hundred times, second batch a hundred times, third batch a hundred times. Like that, it is taking the batches and executing a hundred times. We got it. So what is the difference here where both is equal to zero means no need to see it is something like when you're installing also we write hyphen
[10:11:53] Q, right? Q means silent install. You don't see the execution, how you can see in the Collab Notebook. Where it was is equal to the same thing. It is just integer value. We can say 0, 1, 2, anything, correct? So this is about the fitting model. Once it is done, what should we do now? We need to check for the scores. Scores is equal to model.evaluateTextTest. And we can print accuracy. So we got how much accuracy? 100% we got the accuracy, okay? So this is no need for this parameter. So we got 100% model accurate because the data is very less. For example, here, as I said, if you look into this, every layer, for example, let us say, is that, Yeah, go ahead, Trump.
[10:12:28] But how come showing us accuracy is 100%? After execution, final weights became that. This verbose doesn't have anything dealing with the... No, I'm not talking about verbose equal to one. When we call verbose, then it is printed with accuracy. Accuracy in between 0.8 to 0.9. See, it is started, right? So 0.994, yeah. That is that batch, right? So that means that the range is there between 0.98 to 0.99. Test accuracy is one. No, just let him test accuracy.
[10:13:07] Rama, tell me, what is the question? Then how come it, obviously it has to come here as a 98 or 99, but showing is that the 100% accuracy, how it is possible just, that's what I'm asking. Yeah, Rama, actually at every batch it got some parameters, right? So when it is putting that parameter values, that is the W1, W2 values, it is approximately into one it is going in, okay? So this is like nearby values what you are getting. So for example, 995 you are getting. So these weights, when it is getting into the test accuracy, it was able to achieve 100%.
[10:13:33] Yeah. So we got the accuracy. For example, if you look into this, every layer we set some input to the hidden layer, we have the weights, right? If you want, you can print the weights also. How do you print the weight? For example, model dot, let us take the layers of, for example, first layer is zero, dot get weights. but it is actually a bit late.
[10:13:54] So these are the weights we got it. Okay. And these are the weights for the neurons. So these are the lines we have, right? So every line, we have these weights. And finally the neurons have, this is a value of the neurons with the bias added. Okay. So this way it will move ahead and build the values.
[10:14:13] Clear? So the sequential is now clear? How do you build the sequential model? Any questions here? Can you just explain the weights one with relation to the in? This one, right? So it is something like, for example, I said layer one, correct?
[10:14:30] So layer 1 means we have 4 neurons and then here we have 8. Correct? This is connected to how many? 8 connections total 32. No, no first one only you take. 8 right?
[10:14:48] optimised weights, how many we got, see this one right, layer 0 I said right, layer 0, so how many we got, 1, 2, 3, 4, 5, 6, 7, 8, right, so this is, this is 8, first one, then the
[10:15:07] second neuron third neuron after that we have this one also we have weights right this one z values biases those things also and i get that is 0.449 sure thank you yeah radhika yeah i mean when you are doing this accuracy right at some point it will not improve any
[10:15:27] So, how do we restore the weights at that particular epoch and then use those weights for the validation or testing? Radhika, that is we call it as an early stopping. So, whenever you see that the weights are here, the variations are much, then we can use the
[10:15:46] Early stopping, okay? So Keras provides the option of early stopping. Then you can freeze the weights and you can use it. Can we directly do it in the same function which you have provided or do we have to use a different function? Different functions you have to implement, okay? Okay. Thank you.
[10:16:05] So any other questions? The 100% accuracy, are we to implicitly assume it's over-fitting or? No, it's not over-fitting, Rakesh, because the data is that, right?
[10:16:20] data okay so in other cases maybe you cannot expect but in the iris data it is okay it's not a problem okay okay so sequential is good to go now okay now
[10:16:33] Now the second one we'll get is the functional law. How do you build a functional API? Okay, very simple.
[10:16:49] We include in open close parenthesis, right? Something in the parameters. Yes or no? That may be Python or that may be Java or that may be anything, any programming.
[10:17:07] we use this way, correct? Agree or not? When you see open plus parenthesis, we can say that it is a function, right? So what is functional APIs, second one? It is, we call it as a flexible
[10:17:19] So we can say any layer connects to any other layer. This is a flexibility. Second, we
[10:17:29] multi input and multi output with a shade
[10:17:42] layers. I think till now you didn't see the multi output, right? Generally we use classification is only single classification.
[10:17:53] and it supports complex architecture. It is best for production models and advanced
[10:18:09] it is best. So when I discuss about the sequential, I said prototyping only, correct? That is simple classifier. If you want to do the prototyping, then you can do it, OK?
[10:18:27] As Ashok asked me like memory intensive right so when you get the stack of layers definitely it is a memory intensive but generally in any programming when we do the stack like a number of what you call step by step approach generally it will consume a lot of memory that is the reason we go
[10:18:46] with the functional API, correct? So similar kind in Keras also, we are going to use a functional API so we can reduce the memory constraint. Another thing is sometimes we need to have two outputs and a single input, we need to have two outputs. At that time, we can go with the
[10:19:06] What do you say the functional API? We can use it. Okay, so in that functional API API, how do you build a functional API? We'll see an example and I'll take the same Iris data sample and then I'll build it. So how it comes for example.
[10:19:24] I have 1, 2, 3, 4, same, 8 neurons, 10 neurons, 10 neurons. Now here, output, one, I will take it as a classification. One, I will take it as a regression. Like this, I will take it.
[10:19:42] So that means I want to define this as a classification problem is one and the regression problem I want to. So output is two. So sometimes what happens in the IoT industry, you need to classify whether the particular device is malfunctioning.
[10:20:03] or not, yes or no, for example. Then what is the lifetime of that, for example, 20 hours or 30 hours, we want to mention that also. In that situation, we are going to have two outputs. One is whether we need to understand what is the life, for example, high, low, medium, something.
[10:20:21] Apart from that, how much time it is remained or something. So at the time we need to have two outputs, then we'll go with the functional API. So how do we build the functional API? Let me take the same classical example. I'll stop this one.
[10:20:41] Yeah.
[10:21:03] Okay. For the model train, wondering if there is a way to say.
[10:21:18] run for as long as desired accuracy is reached or it doesn't worsen or if the accuracy doesn't improve by x is 0.5 and let it run for as many epochs.
[10:21:37] It is possible, but for that you have to keep the threshold. And as I said, right, list hopping and you can keep the threshold is not achieved. We can change that. So for that we are having one of the, what do you say, the library called as a Keras library.
[10:21:59] tuner we call it okay so using that it is possible it is similar to hyper parameter tuning what you are saying okay to achieve the good accuracy so for that we have keras tuner you can install keras tuner and give it to that so keras tuner will take care of that and it is going to you know tell like what is the best hyper parameters even start
[10:22:20] from number of epochs and number of you know a split will be there all those things will be that will be given like even in the number of neurons also in the first layer how many you want you can get it okay nice thank you yeah so if you want I will do one thing okay let us take
[10:22:38] Okay, so I want just to do one thing. Once I finish this functional and the last one is the model subclassing, right? So anybody just remind me how you we need to see like, you know, we have a question like, how many number of neurons is
[10:22:59] Just remind me, I will write down the code a little bit so you can see that how it is going to decide the number of neurons and number of layers, okay? So once this is done, three, just remind me before closing the session, so I'll take up that also. I'll write down the code for you. Good.
[10:23:19] Okay, Taran? Yes, yes, yeah. I'm sorry. Okay, no problem. Done. Yeah, perfect. So in C, real time, how we implement, right? So whenever you're taking, if you're understanding, like, you know, any framework you are understanding, if you see, when you
[10:23:37] and when you practically you do it is different. But when you implement in real time production level, then you have to make it production level. How do you make that? We'll see. So first of all, let me take all the imports required similar.
[10:23:50] Here, OK. So in layers, also input already is there, OK.
[10:24:04] OK, then we have Iris loading. Now tell me, do I need to use two categories, yes or no?
[10:24:16] Shall I use two categorical? Yes. Yes. Yes. Why? Because it's a?
[10:24:27] Correct? So still we are using the same thing. So use that. I'll take this part.
[10:24:40] Now, after that, we need to split the data. Splitting data can be done similar X underscore train.
[10:24:53] X underscore test, Y underscore train, Y underscore test is equal train test next, test size. Similarly, we can take 0.2.
[10:25:04] Random state. Test parameter of the training test.
[10:25:16] 0.2. Okay. Okay. Now we need to have a scalar standard scalar.
[10:25:27] Xtest is equal to scalar dot transform. Now is the important part.
[10:25:40] If you see here, after this what we did, we defined the stack of layers, correct?
[10:25:53] Okay, so when we define the stack of layers, here how do we define? First we start with what is the input?
[10:26:08] you have to define input. Okay, input tell me how many parameters we have? Four parameters. So I have given the shape as a
[10:26:25] Then I'll define first layer. Layer L1 is equal. I said dense. How many neurons we have? 8 neurons. And what is activation? Is ReLU. This is layer 1, right? Now what is the layer 2?
[10:26:38] Layer 2 is dense, 10. Activation is relu. Layer 3, same thing, dense, 10 neurons.
[10:26:51] activation is relu final layer four or we can say it is an output statistic
[10:27:03] outputs is equal dense pre activation like this correct yes or no yes okay
[10:27:19] So we define but do you think is there any relationship between the layers? No connectivity, correct? Here if you see the stack of layers, we said we take the model, model.add, then on that
[10:27:37] add on that add on that add so stack of layers they are adding correct but here there is no add so individually we define the layers but how do you make the connection so first layer l1 for example the layer l1 must connect with the input correct
[10:27:57] So how do you make that? I can make it as a parameter said L1. Okay. Now that L1 is nothing but here, what do you have? First one, inputs. So make it as a inputs. Now layer one is connected to inputs, right? Now this must connected to again layer.
[10:28:15] one layer three must connected to layer two now this must connected to layer three now the connection is established correct sir this is another type of layer connection apart from dense dot add yeah functional we are doing selection of
[10:28:33] function in the sense, independent layers, we can add and delete easily, whereas stack of layers, we cannot add in middle, okay? Okay. This is. This is, we don't need to follow the order, correct? Only we need to do the input.
[10:28:50] That's it. According to the input, it is combining, right? Yeah. Okay. So now... One more doubt here. So here we are defining L2 and L3 are the same structure, right? Dense of 10 and L3.
[10:29:07] activation functions. So can't we define one layer and use multiple times as it is a functional call with the different inputs? You can. OK. You can, yeah. But for that instance, we'll be coming here. Perfect. We can do that, yeah. OK.
[10:29:31] to use multi-output, right? Yeah, multi-output, I'll show you that. First, I have written CNOS. Just two minutes, I'll show you, okay? This is without multi-input, just simple input. Same thing I'm trying to mimic. Correct? Now it's okay. So sequential to functional, what I did is okay, correct? You understood now? Same thing,
[10:29:49] Is there any difference between this one and that one apart from the way we have written the code? Code will make a difference, right? Code is the one which is making the differentiation, right? Defining the layers as a function layers. Okay. There also we were stacking
[10:30:09] the layers. Here also we are stacking the layers. What is the difference? Vasantha, they're stacking the layers is like one plate you are keeping and top of that another plate you are keeping, right? Correct. Here we are trying to establish a pointers so that there is a lot of difference in
[10:30:28] pointer connections and establishing one by one. So pointers can be moved from one place to another place, attachment will be there. Whereas if you want to insert in between another plate, it is not possible. Correct? So how can we move these pointers now? Just change the L1, L2.
[10:30:50] So you can change L1 to L2 here just in the function parameter you are passing, correct? That you can change. You define somewhere else, add it here, no problem, right? Okay, got it. That means, I mean, here as of now, the output is same, right? But previous and this one, as of now.
[10:31:11] Yeah, as of now, output is same. Now, just I want to show you that from stacking to functional how we are doing. But I said one of the advantage of using is the multi outputs, right? Two outputs. I will show that, okay? So this is clear now? Architecture level is clear? Yes. There is no change in number of
[10:31:27] trainable parameters right in both the cases yeah if you are using the same number of like you know eight and ten both will be same okay so if you want to see when you say uh here model is equal to model the import
[10:31:39] Here it import the model, sequential. Then I need to import the model also, right?
[10:31:52] Now, model will be inputs is equal to input, output is equal to output. Then, model dot
[10:32:04] You can see same number of parameters. Architecture is same, right? Only the way I'm defining connection is different. Good.
[10:32:19] Okay, so now you have seen the same, but now what I will do instead of using single output, I will try to build two outputs. How do we do that? Let me again start from here.
[10:32:30] So what I will do, I will
[10:32:42] say y is equal to categorical y, I will take it. This is similar, correct? Now I'll try to prepare
[10:32:52] synthetic is equal. Let me import numpy also here.
[10:33:04] Okay, ysynthetic is equal to np.random.rand. I can take the length.
[10:33:15] y then comma like one if you want you can see why synthetic the value so this
[10:33:27] is the regression. So now this is the classification. This is the regression. Now how many outputs we have now?
[10:33:38] one how many outputs we have two outputs correct yes or no yes okay now let us split the data how do you split
[10:33:49] x underscore train okay then x underscore test then y underscore train y underscore
[10:33:59] test, then we need y underscore synthetic train, y synthetic test, train test split,
[10:34:12] X for this one, Y for this one and Y synthetic for this one. Then we have test size 0.2 and
[10:34:26] Then the random state is equal to 42. Done. Splitting is a little bit changed. Any questions in this step? Good to go? OK.
[10:34:42] So now generally we have only one output, right? But how many outputs now I created? Two outputs. One is a classification problem. Second is the regression output. Yeah Ram, go ahead Ram.
[10:34:59] Why are you introducing this Synthetic here? Just to give you an example, how to output, that's it. Synthetic is something like Y1, Y2. Y2 is Synthetic we can assume sir. Just Y2 we can think.
[10:35:17] Can we get some practical example where we have only one input but multiple outputs? Here you can take Vasantha but presently I don't have IoT data. No, no, no. Orally at least. Orally that's what I told you Vasantha.
[10:35:33] like when you're going into IoT, or we can take one example, okay? One example is, okay, good question. So orally you want, right? I'll do one. Okay.
[10:35:45] That is better. So in sequential, let us try. What is a sequential? First in the sequential, one input.
[10:35:59] one output, right? So the model is very simple. What we do, for example, if you are taking an image, we go with the
[10:36:15] solution layer and then we use the max pooling, then we use the dense layer, then we use the softmax. Correct? This is very simple. So, for example, I want to
[10:36:34] I think you might have seen in when you are writing convolution neural network, CNN, plant disease. So there is a bean data in TensorFlow, it is available. So where we can say whether there is a rust or something like that, okay? So what we are doing first, we take the leaf image.
[10:36:55] Then we are going to apply the convolution error, and then we are going to say class label. What is the class? Means what kind of disease that particular leaf is having. So one image at a time, it will take it, and then it is going to give you the answers. Now coming to the functional, as we said, for example, in the
[10:37:15] I can take an image with CNN, then I can take an age, for example, which is a dense, then I'm going to concatenate these two, then we are going to have a dense and output. For example, I have an X-ray image of the person and then age of the person.
[10:37:35] patient age or weight history, something. So now what I'm doing now, I'm trying to concatenate these two combinations. Then finally I'm going to get the output, right? Whether it is any kind of disease, so multiple outputs, something like that. Is that clear now? Yeah. Okay.
[10:37:52] Yes sir. Okay good. Anyone have question here or good to go? So professor here we are getting multiple diseases means multi-class right? What about the? Multi-class. Yeah what about getting two outputs there like. Right.
[10:38:11] What is the disease and what percentage of the disease it is harming? Here you can keep it 2. I have given one example. Outputs can also be 2. For example, pneumonia is there. X-ray image is given and age is given. What percent of the lungs are affected with that?
[10:38:29] for example liver is there. So the first output is whether the person is having pneumonia or not, the second output is the percentage, what percentage of lungs are affected. Exactly. Okay good thank you. So one is the classification, second is the regression or we can
[10:38:44] say this for example the lungs is it we have seen some infection so what do you say what is that infection right so one output is whether the person is having infection in the infection or not. Second we can
[10:39:00] say whether it is a pneumonia or not. Like that also we can have two levels. Okay. Two classifications, two regression, not a problem. Okay. How do you define the model according to that? Okay. So now here
[10:39:16] I need to do the scaling. Scaling generally, we do on features only. So we can say scalar is equal. This part did it. So no changes similar. Now, I need to define in
[10:39:28] Inputs is equal. Input, how many features we have? Poor. So shape is equal. Poor comma.
[10:39:47] Here you can use shape or dimension. If you use dimension directly, you can say four. If you are using shape, you have to give it as a vector. Four gamma means vector. Inputs is done. What is the first layer? Tell me. Dense.
[10:40:00] 8 neurons activation is ReLU then connected to inputs. Second layer activation 10 connected to L2. L3 dense again 10
[10:40:12] Activation is relu and connected to l2. Now we have output.
[10:40:24] one is equal to what is output first output tell me dense three neurons what is the activation here
[10:40:35] Softmax, which is connected to which layer? L3. L3, correct. What happened? Then?
[10:40:45] outputs two which is dense regression problem okay activation
[10:40:55] Which one? Linear. Which is connected to which layer?
[10:41:08] We can use the sigma classification for that here. Outputs one. Output one is the regression problem, right? This output, why is which data you have numerical
[10:41:21] values right okay okay yes or no if you have then you can go with the binary okay okay fine okay okay so it says that past activation is really okay
[10:41:33] Spell mistake. And here give the name also. Name is equal. We can write outputs one. Here
[10:41:42] So here the neural network definition is okay.
[10:41:57] But coming to the back propagation, it will be defined based on how much loss we are doing. So here we are getting two losses, one is categorical loss and one is recursion loss.
[10:42:11] So how optimizer will we do like giving any value add for one thing to do because both will be different functions right lot functions and that getting the new weights will be
[10:42:25] How the back propagation works here? Back propagation for two different functions, two times it will do the back propagation. It will be updated the same whites?
[10:42:40] Yeah, sometimes we'll update the same way depending upon like, you know, how optimized your writing there you can mention inside the function itself. How do you want to use it? Okay.
[10:42:57] Next, Tarun, you have a question. Yeah, so outputs too, we have tied to layer three. Curiosity, you know, we can tie to layer two also, or it always both outputs have to be from the same layer.
[10:43:09] You can. That's what I said. What do you want? You can have less
[10:43:24] number of neurons go to L2. If you want more number of neurons similar go to L3. What's the problem? Problem is not a problem but it will impact the accuracy and other functions.
[10:43:39] definitely definitely will impact because you are decreasing number of neurons accuracy will be go down the question is can we add it or not I said yes we can add it the question is can you can I add
[10:44:02] I said, okay, you can add it, not a problem. But the complexity, you didn't ask me like, you know, whether it is going down or, you know, whether it is going to be okay. That after executing the problem only we know, right, Ashok? So, this is as a functional, wherever you want, you can add it. As I said, the
[10:44:22] pointer, right? Whichever layer you want. For example, for the linear, I want only dense only. Only first layer only I want. Eight neurons is enough. You can add it, not a problem. Correct? Okay. Does this mean like for different, these final classification, we can take the output from different layer?
[10:44:44] Yeah, thanks. Satya. So for each output we have separate neural networks or like the same one will be used? That's what I said, Satya. So you can use same. If you use L3 is the same, right? Somewhere if you want to connect to L2 also not a problem. Different also you can use it. That's what I said.
[10:45:03] So complete all the input to output, complete input to L3, two different will use neural networks because weights will be, back powering will be two, right? So the weights may change. So how do we decide that one? We don't decide. The neural network will take care of those things, right?
[10:45:23] between two outputs which will take something like that. So one beauty of Keras is when you fit automatically back propagation will take care whereas in PyTorch we need to define that is one of the complexity when you're using PyTorch. So there is a reason automatically back propagation and feed forward network is
[10:45:44] take care and care by. When you just say fit, whereas in PyTorch you are defining. So according to the problem statement, according to the layers you are implementing, those things will be taken care of. Okay. So my question is like output one, we have like accuracy, we are getting better accuracy with one of the weights and output two, we are getting better accuracy with another weight.
[10:46:02] We are getting better output with one of the weights which is like in average of both. So it will take the third one? No, both are different. Both different weights it will take. For each output it will take different weights and it will calculate like that.
[10:46:19] confused. I'll show you the same visualization. Okay. Thank you. Yeah. Ashok, what's the question? Sir, my confusion on these outputs too, we took a dents of one because they say regression thing we took one.
[10:46:36] Regression, we took it activation as linear. If you go to the outputs one, we have three different outputs. That's why we took it three and activation as softmax. You mentioned for multivalued you need to take softmax. My question is here for the regression,
[10:46:56] there are huge number of things, that's why we are taking only one. If huge number of things are we are accommodating in one, why don't we, three things we can't accommodate in one and there also why don't we take linear. Wow, Venkat Ashok, you are going back again.
[10:47:15] In classical machine learning, we have a classification and regression, right Ashu? Classification is like, for example, if you have three classes in the target or four classes, that is a classification, correct? Regression is finally, for example, max temperature is given. What is the regression? It is one value only.
[10:47:34] minimum temperature something like that correct finally what you are getting only one value agree then coming to here how many values are getting can we get only one value we are getting out of three we have to define which one is right but whereas here regression is finally only one value whether it's 20 30 21 something like that correct
[10:47:53] so that is the reason regression always single neuron is enough whereas in classification how many you have classes out of that which is the predicted class that is the reason we are going to have a three which is the predicted one which we need to understand right softmax clear sir thank you yeah next yugandhar yeah yeah
[10:48:11] So can we define a functional pointer like dense 10 and relu activation function and define that line number 3 in cell 16? And we can use L2 of that function and L1 and L3 equal to that function pointer of L2? Yes, we can.
[10:48:30] Functions are same like in a function how do we use in classical programming same thing. Okay. So we are using Keras here right and in PyTorch when it works we can actually choose that you want to do the computations with your CPU so Keras do
[10:48:46] take care of it automatically or like yes we need to take care of those things so by default it will go to GPU or like no if GPU is available default it will go to GPU in order to force it okay okay
[10:49:04] Done with the questions? Okay, so I'll do one thing. I'll do like a sample visualization so you'll get the clarity, okay? So now, okay, here let us build the model. How do you build the model? Model is equal.
[10:49:21] model okay inputs is the inputs outputs is how many outputs we have outputs one and outputs two correct build it so once it is built now if want to see the model two different ways we can do it one is for example df dot
[10:49:34] Keras dot utils dot flat model. OK, perfect. Then model. Here I can do file no need. Let us
[10:49:44] layer names is true.
[10:49:54] layer activation is to show shapes
[10:50:04] is true show trainable is
[10:50:13] So now design.
[10:50:26] layer which consists of four neurons. Second layer which consists of four neurons connected with eight trainable. This eight is connected
[10:50:41] connected to 10 trainable. Now from that, it again defined two pointers, right? One is for the output softmax, which is 10 with 3, and next one is an activation is a linear 10 with
[10:50:55] one. Okay. So for example, if I want to see visually, I can say import visual Keras, then visual Keras, there is a
[10:51:05] Let me recall a graph here, okay.
[10:51:14] Model underscore function dot PNG.
[10:51:23] So now you can see, right?
[10:51:34] This is input, this is one output and this is another output. So now the model you have seen visually, you understand?
[10:51:47] that number of neurons and everything correct good to go this is built by the model itself right now we can understand clearly
[10:51:59] how it is building. Does trainable parameters increase since we are having two outputs, weights and biases, output one is different? Yes, definitely.
[10:52:09] Regarding the weights or the number of parameters, they are affected
[10:52:23] in the last layer, right? Previous layer weights are reused for both. Both we can add Jitendra. So both are different, right? One is linear, second is the
[10:52:37] classification. If you have a classification both, then can be, but we are two different types. Yeah, but lastly, I can see that classification, the linear one is affecting one neuron last and that is
[10:52:52] feeding back to the this third layer and so and the top one is also feeding back so then after that all the weights are reused if I back propagate only the last layer
[10:53:05] weights are there are some more weights like one two three four five six seven eight okay i can't count but yeah only the
[10:53:18] these connections are very simple very simple like when we are using pytorch there we need to define feed forward backward everything okay yeah as in
[10:53:31] to define when you write fit, it will take care of all those things. Okay. That operation, it will take care of. And you have seen now very simple.
[10:53:46] like how it is, you know, backpropagating. The visualization, if you build it, the weights automatically think like two different problems that combining in single problem. That's it. Okay. So different when you're
[10:54:02] saying the weights can be distributed according to the model or weight can be reused or they can be again, according to the problem statement, they can be different back propagation can happen. That totally depends upon the problem
[10:54:23] what you are using. The features are very related to this one. Sometimes you can change the features also from X1 to this one for these features for this one, these features for this one. So I can use the L1 input as a two inputs I'm using. For example, I'm different use. But in this case, all
[10:54:46] the weights will be the same weights can come in and you can use it. For example, if I wanted different weights for the different outputs, then input will change. So L1 layer, inputs one, inputs two, you can keep it, and that will be connected to the output. So between the layers is similar. That way, you have two models are combining together, but execution speed will be decreased because two models parallelly, they have to work.
[10:55:05] with different weights, okay? Yes. Yeah. So currently we are seeing this network of density layers, right? Same can be implemented using the convolution layers also, right? Like we are not giving every output to the every neuron. That can be also defined as functional programming here, right? In Keras.
[10:55:23] No, no, see, see, Keras we are talking about together as a framework, right? How do you write a CNN, for example, okay? CNN is what like same neural network only. There if you introduce convolution layer, then after that, max pooling layer and something like, you know, drop
[10:55:43] if you are writing, then that is known as a convolution layer. For example, if you are taking the, for example, you are taking RNN, right? So LSTM, simple RNN, simple LSTM, if you are adding that becomes a RNN. So here, instead of the neurons, in between what you are adding, convolution layers you are adding.
[10:56:04] So how do you add the convolution layer? Sequentially, how do you add the sequential API? If you are using it as a functional, it's a functional API. So how to build that? We are using the framework. Understood? Okay. Clear? So the architecture is different. CNN is architecture. So that architecture, how do you implement in Keras, either functional or the
[10:56:26] sequential or model subclassing. Yeah, yeah. So that's fine. But in CNM, there is a concept called we can split up to the n number of layers for the feature extraction and then densely connected layers, right? That's what I'm saying. Whatever you want to do it, that you can implement in Keras, right? That's what I'm saying. Okay.
[10:56:46] architecture you define. Okay, the way how you are defining whatever the way you define it will accept it, right? Yeah, so I heard something like we can already predefined models on the CNN. So we can cut off and cut the layers from download. So pre trained models, because those definitions like what variables like we can get it, it is advanced or
[10:57:04] It is advanced Uganda, it is not related to this function. Okay. Okay. Thanks. Yeah. Satya. Yes. So, so in the last lecture, in the Sunday, so we got to know that back propagation. So if we take the output as y then dy by dl, l3 and
[10:57:24] DL3 by DL2 and DL2 by DL1 and DL1 by DLX is something we'll do the background equation. So I can see for DY by DL3 we can adjust the weight for the output but DL3 by DL2 we can't adjust it for both
[10:57:39] outputs different one right so it will be a single variation of weights so how did how will it give the weights properly for both outputs linear and the classification is my question yeah i told you two things right just now before with another participant
[10:57:55] ask the same question right yes same question repeating so I told you for example here the single input and I'm trying to connect to the two outputs correct so the same weights can be utilized yes now
[10:58:09] Now, for example, I said this input have four features. These four features are related to Setosa classification and another four features are there which are connected to the output of the regression.
[10:58:24] adding two inputs two different inputs then the two different weights will be there okay but now in this situation it is using the same weights okay for just I'm showing you a classical example how things are working now
[10:58:36] you have to change it. Yes. Good to go now? Yes. Perfect. Vinod? Sir, my question is,
[10:58:49] what purpose you are doing in multiple outputs. If you go for transformers, then it will be easier, right? So we know we are not talking about transformers.
[10:59:06] So here we are talking about Keras framework. Can we do it in two different ways or not? What is the capability of Keras we are discussing now? So when you are saying Keras transformers, we can implement transformer through Keras framework.
[10:59:24] only. So Keras is a framework. So can we build a transformer architecture in Keras? Yes, we can build it. So Keras is again different concept. So here I'm trying to explain you in Keras how many ways we can define the architecture. One is
[10:59:43] the sequence shall be completed, second is the function. How do you transform architecture define? Can we write a transformer architecture Keras? Yes, we can. For example, if you want to train your own large language model, then I can use Keras to build that transformer, encoder, decoder, and everything. I can pass the data.
[11:00:06] build Encyclopedia and then say the small language model, okay? Exactly. I mean, that's what I'm thinking. I mean, it's complicated, I feel, and go for Transformers. Yeah, when you... No, no, no. Don't say go for Transformers. Transformers is an architecture, you know, okay? Yeah. Transformer and architecture. So that architecture we can build through
[11:00:23] Yeah, understood. Now if it is a huge data set, then we can go for it. Again, you're not understanding, you're rotating again. You're looping over only C. Think like CNN is different architecture.
[11:00:41] Now, how do you build CNN? Use Keras. We can build it. Use Keras, we can build CNN, RNN, LSTM. Transformer also I told you, right? Yes. Now, what purpose you are building Transformer for a huge amount of time?
[11:01:03] of data you want to train and build a small language model that is different. What purpose of CNN, an image is given, classify the image. What purpose of RNN, classify the text predictor, the next text, something like that. If the memory is less, I'll go with LSTM, right? So all these concepts we can do with, instead of Python, we can do with Keras, which makes
[11:01:21] you your life easy to build that architecture now understood yeah okay so don't put transformer here transformer is different architecture right with combination of encoder and decoder the purpose of transformer is different purpose of CNN is different purpose of RNN is different so those architectures we can build through Keras easily
[11:01:41] Okay, sorry, I mean, this framework will be applied to Transformers as well. Exactly. Now you got it. Yeah. If you want to build, for example, you said, have you got a lot of documents, I want to build my own language model instead of going for rag or something, then you can use Keras.
[11:02:00] So now we have seen, like functional, we build the architecture functional. Now after that, what we need to do, we need to compile the model, right?
[11:02:19] How do you compile? Model.compile. After this, we'll take a break, okay? I know people are waiting for the break, so we'll just finish it and we'll take the break, okay? So, optimizer, let us take the same, Adam. Now tell me, what is the last?
[11:02:36] Here we have two loss, right? One is categorical, correct? Second is not categorical, not binary. It is a mean square error. So now here we have two losses for the output. Correct one is? Yeah.
[11:02:57] I can understand your, you know, after connecting with you people, so I can understand like next, what is coming in, in the chat, right? So that's what I said, Suresh. So just give me two, three minutes. We'll finish it and we'll take a break. Okay. So outputs one.
[11:03:18] Now, tell me output one is a classification problem, correct? How many classes we have? Three classes, multi-class. So, what type of class we use? Categorical cross entropy. Output two is only one output, right? That is a mean square error we done. Then, coming to the matrix also, like Pasanta said,
[11:03:39] accuracy, right? Now you will get idea clearly. Now matrix tell me, in classification problem, what is the matrix? Accuracy. Whereas in a regression problem, what is accuracy? Mean square error, correct? So we write here, outputs one is classification problem. What should I write?
[11:03:57] accuracy, right? Then coming to outputs two, what do we have? I can take mean average error or mean square error, MSC we call it. Done. This line is clear, model.compile. We have two outputs.
[11:04:19] a categorical output. This is the categorical because three we have. This is the regression. So I just write as a MSC. After model compile, what should we do now? Model.fit. Okay. Now X train is there, right? X train is the common. But Y train, now we have two, right?
[11:04:33] two in the sense outputs one is which one outputs one y-train correct then outputs two y-synthetic train i think right yeah
[11:04:43] Why is synthetic train correct?
[11:04:55] Then similar epochs we can write. Epochs is equal to 100 and batch size will be.
[11:05:08] And then if you want to use TensorFlow, we can say call back, sir. But OK, this is good. OK, verbose.
[11:05:23] Verbose is our wish, right? If you don't write it, it will take you for one. If you write verbose zero, you don't see that.
[11:05:34] Why do we need 100 epochs here when the data is very less?
[11:05:49] What is ideal? Is it like more number of oxides? Ideally more number is good but how many more number is we have to use Keras tuner which will tell you what is the best one.
[11:06:03] So in the deep learning, we can use Keras tuner. See, writing the code is different, optimizing the code is different, and going for the
[11:06:22] So when you are in the industry, for example, in academics what we do, generally we write a simple code, correct? But when it comes to the, for example, industry, the simple code will not go with the production, right?
[11:06:43] So we need to have a code which can go for enterprise ready. So there we need to understand, we cannot spend more time also. Like you know what I'm saying, when your leader is saying that, okay, build a model, you are saying 20 days to build it. And because I'm hyper parameter tuning, I'm looking for different permutation and combinations, right? So instead of that,
[11:07:03] I can use Keras tuner and say that, okay, this is what we got it. So which is like, you know, time you're saving, correct? Yeah. Okay. So then we need to model.evaluate and we can say scores of one, for example, test X test with Y test and Y synthetic test, correct?
[11:07:23] So we can see output one accuracy is how much? 100%. And outputs two accuracy is how much? Mean square error is how much? 0.964 something. Correct. So because we are using same data, definitely we are going to see no classification problem. We are trying to convert into regression. We'll get that mean square error or something like that.
[11:07:42] So in real time, this will be different. So good now. This is a complete functional API. Any questions? Good to go. Give a thumb so I can understand that you are with me. Okay, great. Okay, perfect. So now,
[11:07:59] I understand that you understand two things. One is sequential and the function. Okay. I know people are eagerly waiting for the break. So let us take a break. It's now 1107. Let us come back by 1130. Is it okay?
[11:08:18] 11.30 is good? Yes, perfect. Okay, perfect. Okay. I'll stay here for one, two minutes. Anybody have any questions? You can. This is one basic question. Generally, we use the data, but here
[11:08:33] use it only if it what is the difference I mean why sir only fit below the last few lines you added this one you mean to say not here not to the standard scalar to the model to the model
[11:08:49] the model. Why is it fit? Yeah, model.fit. Generally we use fit and transform, right? No, why fit and transform? Fit and transform is for standard scalar conversion. This is training.
[11:09:03] Training, right? Any model we just tried fit only, right? That's what we learned, right? Yeah, so we did the CNN problem for this hacker
[11:09:18] on thing the biggest trouble there was given a convolution layer filter size what is the output size then feeding that as an input so for the next layer so now when we use this model does it do that automation automatically or we
[11:09:38] still have that burden of input and output size? That's what I'm saying, Tarun. That input and output size, you have to use optimizer functions, right? Keras tuner I'm talking about, right? When you implement Keras tuner, definitely it will take care of those things, okay? Okay.
[11:09:58] Because my hand calculating was very troublesome there. Yeah. Okay. Thank you. Yeah. So Pranali, you can say in sequential, we printed weights model zero, right? So you can write zero zero to get that. Okay. We can get the thing. Yeah. Sharath Chandra. Yes. So last week we learned
[11:10:20] about PyTorch and all those things. And this is like a framework on top of this. So are we using anything more or this will be like the one which we will be using actually in the industry? See, as I told you in the beginning, Sharath, PyTorch is the framework. If you compare now with a Keras, easier you feel, correct? Compared to PyTorch writing.
[11:10:42] It's more like a wrapper on top of all this. So another thing is if you build a PyTorch model bringing to Keras a lot of changes you need to make whereas in Keras is a compatibility easily when you save the model we can put into PyTorch models also. So that is the reason now industry is adapting for the compatibility. So Keras is having more compatibility.
[11:11:00] That is the reason industry is adapting with the Keras. Okay. Okay. Yeah. Raikesh. Yeah. Professor, I have a couple of questions here. Can you go to our lecture? Yeah. Okay. This one or this one? No, yeah, this one.
[11:11:18] So if you see output layer, we have two sets of neurons, one for classification problem and another one for regression problem. Exactly. And if you come to last hidden layer, we have only single set of neurons. That means those neurons in the last hidden layer are doing multiple tasks. Exactly.
[11:11:35] So they're contributing in participation. Yeah. Okay. Yeah, I mean, previous pictures. No, think like, I will tell you, okay. You have a building, okay. So in the building, you have
[11:11:54] You have two doors to enter it and consume whatever you have in that. For example, you are having tea, coffee, then something like that. In one room, you have tea, coffee. In another room, you have some food or something. And coming out of the two different doors, you are coming out.
[11:12:15] architecture is same right but the problem statement the number of neurons instead of repeating they are saying use the same number so in this what happened the parallelly they can work each other instead of rising a different sequential problem parallelly they will work with each other and the same weights will be utilized over there and here and then we are trying to classify and regression right so
[11:12:35] That's where it is useful. Okay. Okay. So it's like feature extraction is same in the last layer. So those features are used by different threads of neurons in the output layer. Exactly. Yeah. Okay. One more small question. Why synthetic we created, right? Yeah, we created it. Yeah. Yeah.
[11:12:57] tampering the data, input data, here in this particular example. Rakesh, this is just to show you an example. Okay, got it. So actually we are tampering the data. Yeah, so that totally understood. Okay, so for example, if I'm teaching you cyber security, definitely I'll tamper chargeability, right? To show you something like, you know, chargeability
[11:13:17] We can be tampered in this way. So that is academic purpose. Similar way, I'm trying to explain you how outputs are there. I didn't took the real one, just a sample. So definitely I'm tampering. Totally agree. Thanks. Yeah, welcome. Yes, Vinod. Go ahead. Sir, one question.
[11:13:39] You said functional APIs and what kind of APIs you're using? What kind of API? The name is functional API. Okay. Application programming interface in the sense they're given like wherever you want, you can integrate in Python or somewhere you can call them. Okay. You create a, using a fast API, you can build a endpoint and call it. Yeah. For example,
[11:14:02] HTTPS and REST APIs. So we are not using any protocols here? No, no, no. Protocols is like when you are converting that into REST API, right? Okay. So this is a functional API why we are saying means easily we can callable that is the name is given API. So it's not actually an API. Okay. So real API is one, once you deploy your model, expose the model
[11:14:30] using REST API, SOAP API, something like that. So when you're exposing an API, then you go with the HTTPS, okay, as a secure or unsecured URL. People can consume your data through the endpoint as a secure or unsecured. So it's going to be synchronous, right? That if you are using fast API, it can be asynchronous. Okay. Thank you.
[11:14:47] First API session at that time, I'll show you everything, don't worry. The deployment session is there, okay? Okay, thanks. Thanks everyone. So we'll take a break and we'll be back, okay?
[11:14:57] You don't know.
[11:15:06] I don't know.
[11:15:15] This is Donakoda.
[11:15:26] I saved a lot for you. I saved a lot for you.
[11:15:36] I am going to hit you. Hit me.
[11:15:46] Okay, thank you.
[11:16:00] Don't look. Don't look.
[11:16:11] Mom, I didn't do much. This is the only marginal. You should sleep here.
[11:16:20] I'm gonna let him down.
[11:16:30] No, no, no, no, no.
[11:16:39] My body's efficient.
[11:16:47] Bye bye.
[11:16:57] Now, we're going to do a little bit more.
[11:17:05] No, no.
[11:17:25] Nanny?
[11:17:35] I don't know.
[11:17:43] Thank you.
[11:17:51] Yes.
[11:18:00] move move
[11:18:14] Bye!
[11:18:22] Leave it there.
[11:18:31] Hi lady.
[11:18:40] I am doing it now.
[11:18:54] It's okay.
[11:19:04] Do you want me to do it?
[11:19:18] I'm sorry.
[11:20:13] What are you doing?
[11:20:21] you
[11:20:36] . So, what is the problem?
[11:20:44] Huh? Huh?
[11:20:53] How do you describe it?
[11:21:03] One more round. One more round. One more.
[11:21:12] Hope it's good.
[11:21:21] Say what do you say my dear?
[11:21:30] I'm here baby.
[11:21:44] I don't know
[11:22:08] Thank you.
[11:22:53] Bye!
[11:23:02] Mmm.
[11:23:13] So I'm going to apply a little bit of cream.
[11:23:28] Is it good? Is it good?
[11:23:38] You have them now. Right, you have one.
[11:23:48] Yeah.
[11:23:58] for joining us live from the
[11:24:07] Okay.
[11:24:16] That's the moment.
[11:24:27] you
[11:24:41] Thank you.
[11:25:16] Okay.
[11:25:50] Mm-hmm.
[11:26:10] It's warm in here.
[11:27:10] for watching.
[11:27:24] Yeah.
